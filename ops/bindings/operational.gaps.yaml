# Operational Gaps - Runtime SSOT Discoveries
#
# These are NOT extraction gaps (see docs/core/AGENTIC_GAP_MAP.md)
# These are issues agents discover DURING work that are out of scope to fix immediately
#
# Review periodically, create cleanup loops for open gaps
#
# Status: authoritative
# Last verified: 2026-02-07

version: 1
updated: "2026-02-07T20:37Z"

gaps:
  # ─────────────────────────────────────────────────────────────
  # Discovered during LOOP-INFRA-VM-RESTRUCTURE-20260206
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-001
    discovered_by: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    discovered_at: "2026-02-07"
    type: stale-ssot
    doc: "ops/bindings/docker.compose.targets.yaml"
    description: |
      Still lists cloudflared, pihole, infisical (secrets) under docker-host
      after Phase 1 migration to infra-core. Services are now on VM 204.
    severity: low
    status: fixed
    fixed_in: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    notes: "Moved cloudflared/pihole/secrets to infra-core target, added vaultwarden"

  - id: GAP-OP-002
    discovered_by: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: "docs/governance/SERVICE_REGISTRY.yaml"
    description: |
      No infisical entry existed before migration. Agent had to discover
      the stack by inspecting Docker containers on docker-host.
    severity: medium
    status: fixed
    fixed_in: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    notes: "Entry added during migration work"

  - id: GAP-OP-003
    discovered_by: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    discovered_at: "2026-02-07"
    type: agent-behavior
    doc: null
    description: |
      Agent guessed path ~/stacks/infisical/ instead of consulting
      docker.compose.targets.yaml binding first. SSOT had the correct
      path (~/stacks/secrets). This is a pattern issue, not a data issue.
    severity: low
    status: open
    fixed_in: null
    notes: "Document 'consult bindings first' pattern in agent guidance"

  - id: GAP-OP-004
    discovered_by: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    discovered_at: "2026-02-07"
    type: duplicate-truth
    doc: "ops/bindings/infra.placement.policy.yaml"
    description: |
      Canonical infra-core/observability services were intended for shop Proxmox
      (pve) but relocation commands relied on manifest values without a
      canonical site/hypervisor placement lock. This allowed wrong-instance
      execution risk when target metadata drifted.
    severity: high
    status: fixed
    fixed_in: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    notes: "Added infra placement policy SSOT + D37 lock + command-time enforcement in relocation/provision scripts"

  - id: GAP-OP-005
    discovered_by: "LOOP-INFRA-VM-RESTRUCTURE-20260206"
    discovered_at: "2026-02-07"
    type: stale-ssot
    doc: "ops/bindings/ssh.targets.yaml"
    description: |
      Hypervisor SSH target IDs are distinct (`pve`, `proxmox-home`) but runtime
      host identity is ambiguous: `proxmox-home` currently reports hostname `pve`.
      This creates decision-risk during relocation/provisioning because agents and
      operators can confuse shop/home hypervisors.
    severity: high
    status: fixed
    fixed_in: "LOOP-GOV-SPINE-SEAL-20260207"
    notes: |
      Guardrail added: infra.hypervisor.identity capability + mutating infra
      preconditions now fail on hostname/machine-id ambiguity. Host-level fix
      applied: proxmox-home canonical hostname updated from `pve` to
      `proxmox-home` via capability `infra.hypervisor.hostname.set`
      (receipt: RCAP-20260207-113039__infra.hypervisor.hostname.set__Rxrbe80548).

  - id: GAP-OP-006
    discovered_by: "LOOP-GOV-SPINE-SEAL-20260207"
    discovered_at: "2026-02-07"
    type: runtime-bug
    doc: "ops/plugins/infra/bin/infra-relocation-preflight"
    description: |
      Preflight host scan silently skipped service source hosts because it used
      an invalid yq expression (`.services[].from_host // empty`) and suppressed
      parser errors. The command also reported missing SSH targets/unreachable
      hosts as informational output instead of a failing gate, allowing
      decision flow to continue without required host evidence.
    severity: high
    status: fixed
    fixed_in: "LOOP-GOV-SPINE-SEAL-20260207"
    notes: |
      Fixed by correcting host extraction, deriving required hosts from active
      VM/service states, and enforcing hard failure on required host/SSOT
      mismatches.

  - id: GAP-OP-007
    discovered_by: "LOOP-GOV-SPINE-SEAL-20260207"
    discovered_at: "2026-02-07"
    type: runtime-bug
    doc: "ops/plugins/infra/bin/infra-relocation-service-transition"
    description: |
      Service and relocation state transitions allowed out-of-order decision
      updates (cutover/migrated) with warning-only behavior. This permitted
      metadata progression even when relocation state had not reached cutover.
    severity: medium
    status: fixed
    fixed_in: "LOOP-GOV-SPINE-SEAL-20260207"
    notes: |
      Transition scripts now hard-fail when relocation state and service/vm
      status are misaligned, and cutover state transition includes an execute-time
      vm readiness gate.

  - id: GAP-OP-008
    discovered_by: "LOOP-GOV-SPINE-SEAL-20260207"
    discovered_at: "2026-02-07"
    type: runtime-bug
    doc: "surfaces/verify/drift-gate.sh"
    description: |
      Top-level `spine.verify` can pass while `infra.hypervisor.identity` fails.
      During active relocation this produces a green global health signal even
      when hypervisor identity ambiguity remains unresolved.
    severity: high
    status: fixed
    fixed_in: "LOOP-GOV-SPINE-SEAL-20260207"
    notes: |
      Added D39 gate (`surfaces/verify/d39-infra-hypervisor-identity-lock.sh`)
      and wired it into `drift-gate.sh`. During active relocation states,
      `spine.verify` now fails if hypervisor identity invariants are violated.

  # ─────────────────────────────────────────────────────────────
  # Discovered during soak-window parallel execution 2026-02-07
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-009
    discovered_by: "soak-window-parallel-execution-20260207"
    discovered_at: "2026-02-07"
    type: stale-ssot
    doc: "surfaces/verify/contracts-gate.sh"
    description: |
      contracts-gate.sh (T5) referenced contracts at docs/ (e.g. docs/RECEIPTS_CONTRACT.md)
      but canonical files live at docs/core/ (e.g. docs/core/RECEIPTS_CONTRACT.md).
      Path mismatch caused ops verify to fail at foundation gate. The files exist;
      the gate paths were stale.
    severity: high
    status: fixed
    fixed_in: "soak-window-parallel-execution-20260207"
    notes: "Fixed contracts-gate.sh paths: docs/ → docs/core/ for all three contracts"

  - id: GAP-OP-010
    discovered_by: "soak-window-parallel-execution-20260207"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: "ops/bindings/ssh.targets.yaml"
    description: |
      media-stack host has docker.compose.targets.yaml binding (ssh_target: media-stack)
      but no corresponding entry in ssh.targets.yaml. Prevents governed SSH access
      for media stack RCA work.
    severity: medium
    status: fixed
    fixed_in: "soak-window-parallel-execution-20260207"
    notes: "Added media-stack target (100.117.1.53, root, shop/pve) to ssh.targets.yaml"

  # ─────────────────────────────────────────────────────────────
  # Discovered during LOOP-HOST-CANONICALIZATION-20260207
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-011
    discovered_by: "LOOP-HOST-CANONICALIZATION-20260207"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: "surfaces/verify/drift-gate.sh"
    description: |
      Hidden-root coverage missing from active drift gates. host.drift.audit
      passes while unmanaged hidden roots and a secret-bearing legacy file
      (~/.config/ronny-ops/env.sh) exist at home root. No gate enforces
      hidden-root inventory or forbidden pattern scanning.
    severity: high
    status: fixed
    fixed_in: "LOOP-HOST-CANONICALIZATION-20260207"
    notes: "D41 hidden-root governance lock + D42 code path case lock + env.sh deleted + backups quarantined"

  # ─────────────────────────────────────────────────────────────
  # Discovered during LOOP-INFRA-CADDY-AUTH-20260207 pre-work
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-012
    discovered_by: "LOOP-INFRA-CADDY-AUTH-20260207"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: "Infisical project: infrastructure (prod)"
    description: |
      Required Authentik bootstrap secrets are not present in Infisical
      infrastructure/prod: AUTHENTIK_SECRET_KEY and AUTHENTIK_DB_PASSWORD.
      This blocks safe execute of staged caddy-auth stack deployment.
    severity: high
    status: fixed
    fixed_in: "LOOP-INFRA-CADDY-AUTH-20260207"
    notes: "Created in infrastructure/prod at /spine/vm-infra/caddy-auth (no root-path duplicates)."

  - id: GAP-OP-013
    discovered_by: "LOOP-INFRA-CADDY-AUTH-20260207"
    discovered_at: "2026-02-07"
    type: duplicate-truth
    doc: "Infisical project: infrastructure (prod)"
    description: |
      Infrastructure project still stores legacy keys at root path `/` (flat
      namespace). This risks future collisions with new VM-infra secrets unless
      all new infra keys are constrained under `/spine/*` namespaces.
    severity: medium
    status: open
    fixed_in: null
    notes: |
      Enforcement added: secrets.namespace.status + secrets.namespace.policy freeze.
      Migration map staged at ops/staged/SECRETS_NAMESPACE_MIGRATION_MAP.md.
      P1 complete for /spine/platform/security (9 root duplicates removed) and
      P2 complete for /spine/network/edge (10 root duplicates removed) and
      P3 complete for /spine/storage/nas (6 root duplicates removed) and
      P4 complete for /spine/integrations/commerce-mail (9 root duplicates removed).
      Root key count reduced from baseline 49 -> 15 (34 removed so far).
      Evidence: ops/staged/SECRETS_NAMESPACE_P1_EXECUTION_20260207.md,
      ops/staged/SECRETS_NAMESPACE_P2_EXECUTION_20260207.md,
      ops/staged/SECRETS_NAMESPACE_P3_EXECUTION_20260207.md,
      ops/staged/SECRETS_NAMESPACE_P4_EXECUTION_20260207.md,
      RCAP-20260207-171547__secrets.p2.root_cleanup.execute__Rchmg11028,
      RCAP-20260207-173400__secrets.namespace.status__Rkd0h38835.

  # ─────────────────────────────────────────────────────────────
  # Discovered during LOOP-GOV-CLI-TOOL-DISCOVERY-20260207
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-014
    discovered_by: "LOOP-GOV-CLI-TOOL-DISCOVERY-20260207"
    discovered_at: "2026-02-07"
    type: agent-behavior
    doc: null
    description: |
      Agent could not discover qrencode despite it being registered in
      maker.tools.inventory.yaml. The tool is domain-scoped (maker plugin)
      with no cross-domain discovery path. Session protocol, brain context,
      and rules all lack tool discovery guidance. Agent searched workbench
      repo, MCP catalogs, and file contents but never found the binding.
    severity: medium
    status: fixed
    fixed_in: "LOOP-GOV-CLI-TOOL-DISCOVERY-20260207"
    notes: |
      Fixed by: cli.tools.inventory.yaml (cross-domain catalog),
      generate-context.sh (tool injection into agent context),
      D44 drift gate (discovery chain validation),
      SESSION_PROTOCOL.md + rules.md updates (agent guidance).

  # ─────────────────────────────────────────────────────────────
  # Discovered during OL_HOME_BASELINE_FINISH audit 2026-02-07
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-015
    discovered_by: "OL_HOME_BASELINE_FINISH"
    discovered_at: "2026-02-07"
    type: runtime-bug
    doc: "docs/governance/MINILAB_SSOT.md"
    description: |
      PVE node-name mismatch on proxmox-home: hostname changed from `pve` to
      `proxmox-home` (GAP-OP-005 fix) but PVE node was not migrated. All VM/LXC
      configs live under /etc/pve/nodes/pve/ while PVE tools look under
      /etc/pve/nodes/proxmox-home/. Breaks qm list, pct list, pct exec, vzdump
      jobs. VMs running pre-rename continue but are unmanageable. VM 101 (immich)
      is stopped and cannot be restarted.
    severity: critical
    status: open
    fixed_in: null
    notes: |
      Root cause: hostname change without PVE node migration. Proxmox node name
      is immutable once set — requires manual config migration or hostname revert.
      Three vzdump backup jobs all disabled and non-functional.

  - id: GAP-OP-017
    discovered_by: "LOOP-GOV-CLAUDE-ENTRYPOINT-LOCK-20260208"
    discovered_at: "2026-02-08"
    type: duplicate-truth
    doc: "~/.claude/CLAUDE.md"
    description: |
      Claude home config (CLAUDE.md, commands/ctx.md, settings.json, settings.local.json)
      contains standalone governance sections (Authority Order, Immutable Invariants, etc.)
      and uppercase ~/Code/ path references. No Claude-equivalent of D32 (Codex instruction
      source lock) exists. Runtime scripts reference .brain/ paths but no .brain/ directory
      exists — actual files live at docs/brain/. SESSION_PROTOCOL.md also references .brain/.
    severity: medium
    status: fixed
    fixed_in: "LOOP-GOV-CLAUDE-ENTRYPOINT-LOCK-20260208"
    notes: |
      Fixed by: CLAUDE.md rewritten to redirect shim, path case canonicalized across
      all governed Claude files, .brain/ references replaced with docs/brain/ in runtime
      scripts and SESSION_PROTOCOL.md, D46 + D47 drift gates added, agent.entrypoint.lock.yaml
      binding created, host-claude-entrypoint-lock plugin with status/enforce/execute modes.

  # ─────────────────────────────────────────────────────────────
  # Discovered during PVE baseline SSH audit 2026-02-07
  # ─────────────────────────────────────────────────────────────

  - id: GAP-OP-018
    discovered_by: "OL_SHOP_BASELINE_FINISH"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: "/etc/pve/jobs.cfg"
    description: |
      VM 204 (infra-core) is not included in the vzdump backup job on pve.
      The job covers VMs 200-203 but was created before VM 204 existed.
      infra-core runs cloudflared, pihole, infisical, vaultwarden, caddy,
      and authentik — all critical services with no hypervisor-level backup.
    severity: high
    status: open
    fixed_in: null
    notes: |
      Fix: add vmid 204 to vzdump job in /etc/pve/jobs.cfg. Requires a
      mutating capability (none exists yet). Also consider adding VM 205
      (observability) when provisioned.

  - id: GAP-OP-019
    discovered_by: "OL_SHOP_BASELINE_FINISH"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: "pve crontab"
    description: |
      No ZFS scrub scheduled for the media pool on pve. Only the tank pool
      has a weekly scrub (`0 3 * * 0 zpool scrub tank`). The media pool's
      last scrub was CANCELED on 2026-01-11. Media pool is RAIDZ1 with 4x
      Seagate ST8000AS0002 (SMR archive drives) — higher risk profile than
      tank (RAIDZ2 enterprise SAS).
    severity: medium
    status: open
    fixed_in: null
    notes: |
      Fix: add `0 4 * * 0 zpool scrub media` to pve crontab. Requires
      mutating capability. SMR drives + RAIDZ1 + no scrub = elevated
      silent corruption risk.

  - id: GAP-OP-016
    discovered_by: "OL_HOME_BASELINE_FINISH"
    discovered_at: "2026-02-07"
    type: missing-entry
    doc: null
    description: |
      No naming governance policy exists. Hostname, PVE node name, Tailscale
      hostname, ssh.targets.yaml ID, and DEVICE_IDENTITY_SSOT entries are all
      managed independently with no canonical mapping or rename procedure.
      This caused GAP-OP-015 (hostname changed without PVE node migration)
      and has caused repeated confusion (media-stack site attribution, hypervisor
      identity ambiguity).
    severity: high
    status: fixed
    fixed_in: "LOOP-NAMING-GOVERNANCE-20260207"
    notes: |
      Fixed by: naming.policy.yaml (canonical names + surface authority + rename
      procedure + allowed exceptions) + D45 naming consistency lock gate
      (cross-file verification wired into drift-gate.sh). Also fixed vault kind
      misclassification (lxc→vm) in placement policy and DEVICE_IDENTITY_SSOT.

# ─────────────────────────────────────────────────────────────
# Gap Types
# ─────────────────────────────────────────────────────────────
#
# stale-ssot      - Doc has outdated information
# missing-entry   - Expected entry doesn't exist
# agent-behavior  - Agent pattern that caused friction (not a doc issue)
# unclear-doc     - Doc exists but is ambiguous or incomplete
# duplicate-truth - Multiple docs claim authority for same thing
# runtime-bug     - Runtime implementation behavior violates governance intent
