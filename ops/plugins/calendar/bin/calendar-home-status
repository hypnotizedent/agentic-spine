#!/usr/bin/env python3
"""calendar-home-status - verify governed local calendar home contract and runtime status."""

from __future__ import annotations

import argparse
import json
import os
import re
import subprocess
import sys
import time
from pathlib import Path
from typing import Any

import yaml


def fail(msg: str, code: int = 1) -> None:
    print(f"ERROR: {msg}", file=sys.stderr)
    raise SystemExit(code)


def load_yaml(path: Path) -> dict[str, Any]:
    if not path.is_file():
        fail(f"missing contract: {path}")
    try:
        payload = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
    except Exception as exc:  # pragma: no cover - runtime guard
        fail(f"unable to parse YAML {path}: {exc}")
    if not isinstance(payload, dict):
        fail(f"YAML root must be mapping: {path}")
    return payload


def parse_stack_map(path: Path, stack_id: str) -> dict[str, str]:
    if not path.is_file():
        fail(f"missing workbench stack map: {path}")

    lookup = {
        "METHOD": "method",
        "HOST": "host",
        "PATH": "path",
        "COMPOSE_FILE": "compose_file",
        "ENV_FILE": "env_file",
    }
    values: dict[str, str] = {}
    pattern = re.compile(r'^DEPLOY_STACK_([A-Z_]+)\[' + re.escape(stack_id) + r'\]="([^"]*)"$')

    for line in path.read_text(encoding="utf-8", errors="ignore").splitlines():
        match = pattern.match(line.strip())
        if not match:
            continue
        key = lookup.get(match.group(1), "")
        if key:
            values[key] = match.group(2)

    return values


def ssh_ok(host: str, cmd: str, timeout_sec: int = 10) -> tuple[bool, str]:
    proc = subprocess.run(
        ["ssh", "-o", "BatchMode=yes", "-o", f"ConnectTimeout={timeout_sec}", host, cmd],
        capture_output=True,
        text=True,
        check=False,
    )
    output = (proc.stdout or proc.stderr or "").strip()
    return proc.returncode == 0, output


def main() -> None:
    script_dir = Path(__file__).resolve().parent
    root = Path(os.environ.get("SPINE_ROOT", str(script_dir.parents[3]))).expanduser().resolve()

    parser = argparse.ArgumentParser(description="Verify local calendar home contract + runtime")
    parser.add_argument("--json", action="store_true", help="Emit JSON status")
    parser.add_argument("--skip-runtime", action="store_true", help="Validate contract/parity only")
    args = parser.parse_args()

    home_contract_path = root / "ops/bindings/calendar.home.contract.yaml"
    sync_contract_path = root / "ops/bindings/calendar.sync.contract.yaml"

    workbench_root = Path(
        os.environ.get("WORKBENCH_ROOT", "/Users/ronnyworks/code/workbench")
    ).expanduser().resolve()
    stack_map_path = workbench_root / "scripts/root/deploy/stack-map.sh"

    home = load_yaml(home_contract_path)
    sync = load_yaml(sync_contract_path)

    home_section = home.get("home") if isinstance(home.get("home"), dict) else {}
    endpoint = home_section.get("endpoint") if isinstance(home_section.get("endpoint"), dict) else {}
    local_store = (
        home_section.get("local_writable_store")
        if isinstance(home_section.get("local_writable_store"), dict)
        else {}
    )

    provider = str(home_section.get("provider", "")).strip()
    host = str(home_section.get("host", "")).strip()
    stack_id = str(home_section.get("stack_id", "")).strip()
    remote_stack_path = str(home_section.get("remote_stack_path", "")).strip()
    write_mode = str(home_section.get("write_mode", "")).strip()
    base_url = str(endpoint.get("base_url", "")).strip()
    healthcheck_url = str(endpoint.get("healthcheck_url", "")).strip()
    collection = str(endpoint.get("calendar_collection", "")).strip()
    store_path = str(local_store.get("path", "")).strip()

    sync_home = sync.get("local_calendar_home") if isinstance(sync.get("local_calendar_home"), dict) else {}
    sync_push_caps = (
        sync.get("sync_contracts", {}).get("push_write_capabilities", [])
        if isinstance(sync.get("sync_contracts"), dict)
        else []
    )

    checks: list[str] = []
    errors: list[str] = []

    if provider != "communications-calendar":
        errors.append(f"home.provider must be communications-calendar (actual={provider!r})")
    else:
        checks.append("provider=communications-calendar")

    if host != "communications-stack":
        errors.append(f"home.host must be communications-stack (actual={host!r})")
    else:
        checks.append("host=communications-stack")

    if stack_id != "communications-calendar":
        errors.append(f"home.stack_id must be communications-calendar (actual={stack_id!r})")
    else:
        checks.append("stack_id=communications-calendar")

    if write_mode != "local-only":
        errors.append(f"home.write_mode must be local-only (actual={write_mode!r})")
    else:
        checks.append("write_mode=local-only")

    if sync_home.get("contract_ref") != "ops/bindings/calendar.home.contract.yaml":
        errors.append("calendar.sync.contract local_calendar_home.contract_ref mismatch")
    else:
        checks.append("sync contract_ref parity")

    if sync_home.get("provider") != "communications-calendar":
        errors.append("calendar.sync.contract local_calendar_home.provider mismatch")
    else:
        checks.append("sync provider parity")

    if sync_home.get("write_mode") != "local-only":
        errors.append("calendar.sync.contract local_calendar_home.write_mode must be local-only")
    else:
        checks.append("sync write_mode parity")

    if not isinstance(sync_push_caps, list):
        errors.append("calendar.sync.contract sync_contracts.push_write_capabilities must be a list")
    elif sync_push_caps:
        errors.append(f"calendar.sync.contract push_write_capabilities must remain empty (actual={sync_push_caps})")
    else:
        checks.append("microsoft push_write_capabilities empty")

    stack_map = parse_stack_map(stack_map_path, stack_id or "communications-calendar")
    if stack_map.get("method") != "docker_compose_ssh":
        errors.append("workbench stack-map method for communications-calendar must be docker_compose_ssh")
    else:
        checks.append("stack-map method parity")

    if stack_map.get("host") != "communications-stack":
        errors.append("workbench stack-map host for communications-calendar must be communications-stack")
    else:
        checks.append("stack-map host parity")

    if stack_map.get("path") != "/opt/stacks/communications-stack/calendar":
        errors.append("workbench stack-map path for communications-calendar mismatch")
    else:
        checks.append("stack-map path parity")

    if stack_map.get("compose_file") != "docker-compose.yml":
        errors.append("workbench stack-map compose file for communications-calendar must be docker-compose.yml")
    else:
        checks.append("stack-map compose file parity")

    runtime_checks: dict[str, Any] = {
        "runtime_checked": not args.skip_runtime,
        "stack_running": False,
        "endpoint_reachable": False,
        "stack_services": "",
        "runtime_errors": [],
    }

    if not args.skip_runtime and not errors:
        compose_ps_cmd = (
            f"cd {remote_stack_path} && "
            "docker compose -f docker-compose.yml ps --services --filter status=running"
        )
        ok, out = ssh_ok(host, compose_ps_cmd)
        if not ok:
            runtime_checks["runtime_errors"].append(
                f"unable to query stack runtime on {host}: {out or 'ssh failure'}"
            )
        else:
            runtime_checks["stack_services"] = out
            runtime_checks["stack_running"] = bool(out.strip())
            if not runtime_checks["stack_running"]:
                runtime_checks["runtime_errors"].append("no running services in communications-calendar stack")

        endpoint_cmd = f"curl -fsS {healthcheck_url or base_url} >/dev/null"
        ok, out = ssh_ok(host, endpoint_cmd)
        if not ok:
            runtime_checks["runtime_errors"].append(
                f"calendar endpoint probe failed on {host}: {out or 'curl failure'}"
            )
        else:
            runtime_checks["endpoint_reachable"] = True

        if runtime_checks["runtime_errors"]:
            errors.extend(runtime_checks["runtime_errors"])
        else:
            checks.append("runtime stack + endpoint availability")

    status = "ok" if not errors else "fail"
    payload = {
        "capability": "calendar.home.status",
        "status": status,
        "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "data": {
            "spine_root": str(root),
            "workbench_root": str(workbench_root),
            "home_contract": str(home_contract_path),
            "sync_contract": str(sync_contract_path),
            "provider": provider,
            "host": host,
            "stack_id": stack_id,
            "remote_stack_path": remote_stack_path,
            "write_mode": write_mode,
            "base_url": base_url,
            "calendar_collection": collection,
            "local_store_path": store_path,
            "checks": checks,
            "errors": errors,
            "runtime": runtime_checks,
        },
    }

    if args.json:
        print(json.dumps(payload, indent=2, sort_keys=True))
    else:
        print("calendar.home.status")
        print(f"provider: {provider}")
        print(f"host: {host}")
        print(f"stack_id: {stack_id}")
        print(f"remote_stack_path: {remote_stack_path}")
        print(f"write_mode: {write_mode}")
        print(f"endpoint: {healthcheck_url or base_url}")
        print(f"workbench_stack_map: {stack_map_path}")
        print(f"checks_passed: {len(checks)}")
        print(f"errors: {len(errors)}")
        if checks:
            print("checks:")
            for check in checks:
                print(f"  - {check}")
        if errors:
            print("errors:")
            for err in errors:
                print(f"  - {err}")
        print(f"status: {status.upper()}")

    raise SystemExit(0 if status == "ok" else 1)


if __name__ == "__main__":
    main()
