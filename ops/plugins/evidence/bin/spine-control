#!/usr/bin/env python3
"""spine-control

Unified control-loop surfaces:
  - spine.control.tick
  - spine.control.plan
  - spine.control.execute
  - spine.control.cycle
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import os
import re
import subprocess
import sys
from collections import Counter
from pathlib import Path
from typing import Any

import yaml


ROOT = Path(__file__).resolve().parents[4]
SCHEMA_VERSION = "1.0"
VERIFY_PASS_STATUSES = {"done", "pass", "passed", "ok", "healthy", "success"}
VERIFY_FAIL_STATUSES = {"failed", "fail", "error", "incident", "critical"}


def utc_now() -> str:
    return dt.datetime.now(dt.timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def run_cmd(cmd: list[str], *, cwd: Path | None = None, input_text: str | None = None) -> tuple[int, str, str]:
    proc = subprocess.run(
        cmd,
        cwd=str(cwd or ROOT),
        input=input_text,
        text=True,
        capture_output=True,
        check=False,
    )
    return proc.returncode, proc.stdout, proc.stderr


def parse_frontmatter(path: Path) -> dict[str, str]:
    text = path.read_text(encoding="utf-8")
    if not text.startswith("---\n"):
        return {}
    parts = text.split("---", 2)
    if len(parts) < 3:
        return {}
    front = parts[1]
    data: dict[str, str] = {}
    for line in front.splitlines():
        if ":" not in line:
            continue
        key, value = line.split(":", 1)
        data[key.strip()] = value.strip().strip('"').strip("'")
    return data


def load_yaml(path: Path, default: Any) -> Any:
    if not path.exists():
        return default
    with path.open("r", encoding="utf-8") as fh:
        loaded = yaml.safe_load(fh)
    return default if loaded is None else loaded


def resolve_runtime_paths() -> dict[str, Path]:
    contract = load_yaml(ROOT / "ops/bindings/mailroom.runtime.contract.yaml", {})
    runtime_active = bool(contract.get("active"))
    runtime_root = str(contract.get("runtime_root", "")).strip()

    inbox = os.environ.get("SPINE_INBOX")
    outbox = os.environ.get("SPINE_OUTBOX")
    state = os.environ.get("SPINE_STATE")
    logs = os.environ.get("SPINE_LOGS")

    if runtime_active and runtime_root:
        inbox = inbox or f"{runtime_root}/inbox"
        outbox = outbox or f"{runtime_root}/outbox"
        state = state or f"{runtime_root}/state"
        logs = logs or f"{runtime_root}/logs"

    inbox = inbox or str(ROOT / "mailroom/inbox")
    outbox = outbox or str(ROOT / "mailroom/outbox")
    state = state or str(ROOT / "mailroom/state")
    logs = logs or str(ROOT / "mailroom/logs")

    return {
        "inbox": Path(inbox),
        "outbox": Path(outbox),
        "state": Path(state),
        "logs": Path(logs),
    }


def severity_rank(value: str) -> int:
    order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
    return order.get((value or "").strip().lower(), 4)


def gap_numeric_id(value: str) -> int:
    m = re.search(r"(\d+)$", value or "")
    return int(m.group(1)) if m else 999_999


def collect_open_loops() -> list[dict[str, Any]]:
    rc, out, _ = run_cmd([str(ROOT / "bin/ops"), "loops", "list", "--open"], cwd=ROOT)
    if rc != 0:
        return []

    open_ids: list[str] = []
    for line in out.splitlines():
        m = re.search(r"(LOOP-[A-Z0-9-]+)", line)
        if m:
            open_ids.append(m.group(1))

    loop_dir = ROOT / "mailroom/state/loop-scopes"
    rows: list[dict[str, Any]] = []
    for loop_id in open_ids:
        path = loop_dir / f"{loop_id}.scope.md"
        front = parse_frontmatter(path) if path.exists() else {}
        rows.append(
            {
                "loop_id": loop_id,
                "status": (front.get("status") or "open").strip().lower(),
                "owner": front.get("owner", ""),
                "priority": front.get("priority", ""),
                "objective": front.get("objective", ""),
                "path": str(path.relative_to(ROOT)) if path.exists() else "",
            }
        )
    return rows


def collect_open_gaps() -> list[dict[str, Any]]:
    data = load_yaml(ROOT / "ops/bindings/operational.gaps.yaml", {})
    rows = []
    for item in data.get("gaps", []):
        status = str(item.get("status", "")).strip().lower()
        if status not in {"open", "active"}:
            continue
        desc = str(item.get("description", "")).strip()
        desc = re.sub(r"\s+", " ", desc)
        rows.append(
            {
                "id": item.get("id", ""),
                "severity": item.get("severity", "medium"),
                "status": status,
                "parent_loop": item.get("parent_loop", ""),
                "description": desc,
                "doc": item.get("doc", ""),
            }
        )
    rows.sort(key=lambda r: (severity_rank(r.get("severity", "")), gap_numeric_id(r.get("id", ""))))
    return rows


def parse_proposals_summary() -> dict[str, int]:
    script = ROOT / "ops/plugins/proposals/bin/proposals-status"
    if not script.exists():
        return {
            "total": 0,
            "pending": 0,
            "applied": 0,
            "superseded": 0,
            "draft_hold": 0,
            "draft": 0,
            "read_only": 0,
            "invalid": 0,
            "sla_breaches": 0,
        }

    rc, out, err = run_cmd([str(script)], cwd=ROOT)
    text = out if out.strip() else err
    summary = {
        "total": 0,
        "pending": 0,
        "applied": 0,
        "superseded": 0,
        "draft_hold": 0,
        "draft": 0,
        "read_only": 0,
        "invalid": 0,
        "sla_breaches": 0,
    }
    patterns = {
        "total": r"Total:\s+(\d+)",
        "pending": r"Pending:\s+(\d+)",
        "applied": r"Applied:\s+(\d+)",
        "superseded": r"Superseded:\s+(\d+)",
        "draft_hold": r"Draft Hold:\s+(\d+)",
        "draft": r"Draft:\s+(\d+)",
        "read_only": r"Read-only:\s+(\d+)",
        "invalid": r"Invalid:\s+(\d+)",
        "sla_breaches": r"SLA breaches:\s+(\d+)",
    }
    for key, pattern in patterns.items():
        m = re.search(pattern, text)
        if m:
            summary[key] = int(m.group(1))
    if rc != 0 and summary["total"] == 0:
        summary["invalid"] = max(summary["invalid"], 1)
    return summary


def parse_json_output(script: Path, args: list[str]) -> tuple[int, dict[str, Any]]:
    rc, out, err = run_cmd([str(script)] + args, cwd=ROOT)
    text = out.strip() or err.strip()
    if not text:
        return rc, {}
    try:
        payload = json.loads(text)
    except json.JSONDecodeError:
        payload = {"status": "error", "error": {"message": text}}
    return rc, payload


def collect_calendar_status() -> dict[str, Any]:
    script = ROOT / "ops/plugins/calendar/bin/calendar-status"
    if not script.exists():
        return {"status": "error", "error": {"message": "calendar-status script not found"}}
    _, payload = parse_json_output(script, ["--json"])
    if not payload:
        return {"status": "error", "error": {"message": "calendar-status returned no payload"}}
    data = payload.get("data", {})
    return {
        "status": payload.get("status", "unknown"),
        "binding_valid": bool(data.get("binding_valid")),
        "missing_count": len(data.get("missing", []) or []),
        "stale_count": len(data.get("stale", []) or []),
        "missing": data.get("missing", []) or [],
        "stale": data.get("stale", []) or [],
    }


def collect_alert_status() -> dict[str, Any]:
    script = ROOT / "ops/plugins/alerting/bin/alerting-status"
    if not script.exists():
        return {
            "status": "error",
            "active_alerts": 0,
            "active_warn_alerts": 0,
            "active_incident_alerts": 0,
            "total_alerts": 0,
            "active_domains": [],
        }
    _, payload = parse_json_output(script, ["--json"])
    domains = payload.get("domains", []) if isinstance(payload, dict) else []
    active = []
    total_alerts = 0
    active_alerts = 0
    active_warn_alerts = 0
    active_incident_alerts = 0
    for d in domains:
        total_alerts += int(d.get("alerts_total", d.get("alerts", 0)) or 0)
        active_count = int(d.get("active_alerts", 0) or 0)
        if active_count <= 0:
            # Backward-compat fallback for older alerting-status payloads.
            legacy_alerts = int(d.get("alerts", 0) or 0)
            if legacy_alerts > 0:
                active_count = legacy_alerts
        if active_count > 0:
            active.append(d.get("domain", ""))
            active_alerts += active_count
        active_warn_alerts += int(d.get("active_warn_alerts", 0) or 0)
        active_incident_alerts += int(d.get("active_incident_alerts", 0) or 0)
    alert_status = "ok"
    if active_incident_alerts > 0:
        alert_status = "error"
    elif active_alerts > 0:
        alert_status = "warn"
    return {
        "status": alert_status,
        "active_alerts": active_alerts,
        "active_warn_alerts": active_warn_alerts,
        "active_incident_alerts": active_incident_alerts,
        "total_alerts": total_alerts,
        "active_domains": active,
        "domains": domains,
    }


def collect_handoff_status() -> dict[str, Any]:
    script = ROOT / "ops/plugins/handoff/bin/session-handoff-status"
    if not script.exists():
        return {"active": 0, "closed": 0, "expired": 0}
    _, payload = parse_json_output(script, ["--json"])
    return {
        "active": int(payload.get("active", 0) or 0),
        "closed": int(payload.get("closed", 0) or 0),
        "expired": int(payload.get("expired", 0) or 0),
    }


def normalize_run_status(value: Any) -> str:
    status = str(value or "").strip().lower()
    if status in VERIFY_PASS_STATUSES:
        return "done"
    if status in VERIFY_FAIL_STATUSES:
        return "failed"
    return status or "unknown"


def summarize_verify_health(events: list[dict[str, Any]]) -> dict[str, Any]:
    verify_events = [e for e in events if str(e.get("capability", "")).startswith("verify.")]
    verify_failed = [e for e in verify_events if normalize_run_status(e.get("status", "")) == "failed"]

    latest_by_capability: dict[str, dict[str, Any]] = {}
    for event in verify_events:
        capability = str(event.get("capability", "")).strip()
        if capability and capability not in latest_by_capability:
            latest_by_capability[capability] = event

    current_failed_caps: list[dict[str, str]] = []
    for capability, event in latest_by_capability.items():
        normalized = normalize_run_status(event.get("status", ""))
        if normalized != "failed":
            continue
        current_failed_caps.append(
            {
                "capability": capability,
                "created_at": str(event.get("created_at", "")),
                "status": str(event.get("status", "")),
                "summary": str(event.get("summary", "")),
            }
        )
    current_failed_caps.sort(key=lambda row: (row.get("created_at", ""), row.get("capability", "")), reverse=True)

    latest_verify = verify_events[0] if verify_events else {}
    core_latest = next((e for e in verify_events if str(e.get("capability", "")) == "verify.core.run"), {})
    core_latest_status = normalize_run_status(core_latest.get("status", "")) if core_latest else "unknown"

    return {
        "verify_total_runs": len(verify_events),
        "verify_failed_runs": len(verify_failed),
        "verify_current_failed_runs": len(current_failed_caps),
        "verify_current_failed_capabilities": current_failed_caps,
        "verify_latest_status": normalize_run_status(latest_verify.get("status", "")) if latest_verify else "unknown",
        "verify_latest_capability": str(latest_verify.get("capability", "")) if latest_verify else "",
        "verify_latest_created_at": str(latest_verify.get("created_at", "")) if latest_verify else "",
        "core_verify_latest_status": core_latest_status,
        "core_verify_latest_created_at": str(core_latest.get("created_at", "")) if core_latest else "",
        "core_verify_needs_attention": core_latest_status == "failed",
    }


def collect_timeline(window_hours: int) -> dict[str, Any]:
    script = ROOT / "ops/plugins/evidence/bin/spine-timeline-query"
    if not script.exists():
        return {
            "event_count": 0,
            "verify_total_runs": 0,
            "verify_failed_runs": 0,
            "verify_current_failed_runs": 0,
            "verify_current_failed_capabilities": [],
            "verify_latest_status": "unknown",
            "verify_latest_capability": "",
            "verify_latest_created_at": "",
            "core_verify_latest_status": "unknown",
            "core_verify_latest_created_at": "",
            "core_verify_needs_attention": False,
            "recent_failures": [],
        }
    rc, payload = parse_json_output(script, ["--since", f"{window_hours}h", "--limit", "200", "--format", "json"])
    if rc != 0 and "events" not in payload:
        return {
            "event_count": 0,
            "verify_total_runs": 0,
            "verify_failed_runs": 0,
            "verify_current_failed_runs": 0,
            "verify_current_failed_capabilities": [],
            "verify_latest_status": "unknown",
            "verify_latest_capability": "",
            "verify_latest_created_at": "",
            "core_verify_latest_status": "unknown",
            "core_verify_latest_created_at": "",
            "core_verify_needs_attention": False,
            "recent_failures": [],
        }

    events = payload.get("events", []) if isinstance(payload, dict) else []
    verify_health = summarize_verify_health(events)
    all_failed = [e for e in events if str(e.get("status", "")).lower() == "failed"]
    cap_counts = Counter(str(e.get("capability", "")) for e in events if e.get("capability"))

    return {
        "window_hours": window_hours,
        "event_count": len(events),
        "verify_total_runs": verify_health.get("verify_total_runs", 0),
        "verify_failed_runs": verify_health.get("verify_failed_runs", 0),
        "verify_current_failed_runs": verify_health.get("verify_current_failed_runs", 0),
        "verify_current_failed_capabilities": verify_health.get("verify_current_failed_capabilities", []),
        "verify_latest_status": verify_health.get("verify_latest_status", "unknown"),
        "verify_latest_capability": verify_health.get("verify_latest_capability", ""),
        "verify_latest_created_at": verify_health.get("verify_latest_created_at", ""),
        "core_verify_latest_status": verify_health.get("core_verify_latest_status", "unknown"),
        "core_verify_latest_created_at": verify_health.get("core_verify_latest_created_at", ""),
        "core_verify_needs_attention": bool(verify_health.get("core_verify_needs_attention", False)),
        "recent_failures": [
            {
                "created_at": e.get("created_at", ""),
                "capability": e.get("capability", ""),
                "status": e.get("status", ""),
                "summary": e.get("summary", ""),
            }
            for e in all_failed[:10]
        ],
        "top_capabilities": [{"capability": k, "count": v} for k, v in cap_counts.most_common(10)],
        "source_counts": payload.get("source_counts", {}),
    }


def collect_graph_summary() -> dict[str, Any]:
    script = ROOT / "ops/plugins/evidence/bin/spine-graph-show"
    if not script.exists():
        return {"status": "error", "view_id": "", "node_count": 0, "edge_count": 0}

    rc, payload = parse_json_output(script, ["--format", "json"])
    if rc != 0 and not payload:
        return {"status": "error", "view_id": "", "node_count": 0, "edge_count": 0}

    nodes = payload.get("nodes", []) if isinstance(payload, dict) else []
    edges = payload.get("edges", []) if isinstance(payload, dict) else []
    view = payload.get("view", {}) if isinstance(payload, dict) else {}
    return {
        "status": "ok" if isinstance(payload, dict) else "error",
        "view_id": view.get("id", ""),
        "node_count": len(nodes),
        "edge_count": len(edges),
    }


def collect_comms_queue_status() -> dict[str, Any]:
    script = ROOT / "ops/plugins/communications/bin/communications-alerts-runtime-status"
    if not script.exists():
        return {
            "slo_status": "unknown",
            "queue_pending_count": 0,
            "queue_oldest_age_seconds": 0,
            "escalation_recommended": False,
            "pending_escalation_task_count": 0,
            "oneliner": "",
        }
    _, payload = parse_json_output(script, ["--json"])
    if not payload:
        return {
            "slo_status": "unknown",
            "queue_pending_count": 0,
            "queue_oldest_age_seconds": 0,
            "escalation_recommended": False,
            "pending_escalation_task_count": 0,
            "oneliner": "",
        }
    data = payload.get("data", {})
    return {
        "slo_status": str(data.get("slo_status", "unknown")),
        "queue_pending_count": int(data.get("queue_pending_count", 0) or 0),
        "queue_oldest_age_seconds": int(data.get("queue_oldest_age_seconds", 0) or 0),
        "escalation_recommended": bool(data.get("escalation_recommended", False)),
        "pending_escalation_task_count": int(data.get("pending_escalation_task_count", 0) or 0),
        "last_escalation_at": str(data.get("last_escalation_at", "")),
        "last_escalation_fingerprint": str(data.get("last_escalation_fingerprint", "")),
        "oneliner": str(data.get("oneliner", "")),
    }


def collect_launchd_scheduler_status() -> dict[str, Any]:
    script = ROOT / "ops/plugins/host/bin/launchd-scheduler-health-status"
    if not script.exists():
        return {
            "status": "error",
            "summary": {"total": 0, "ok": 0, "stale": 0, "failed": 0, "unknown": 0},
            "stale_labels": [],
            "failed_labels": [],
            "unknown_labels": [],
            "error": {"message": f"missing script: {script}"},
        }
    _, payload = parse_json_output(script, ["--json"])
    if not payload:
        return {
            "status": "error",
            "summary": {"total": 0, "ok": 0, "stale": 0, "failed": 0, "unknown": 0},
            "stale_labels": [],
            "failed_labels": [],
            "unknown_labels": [],
            "error": {"message": "launchd scheduler status returned no payload"},
        }
    data = payload.get("data", {}) if isinstance(payload, dict) else {}
    summary = data.get("summary", {}) if isinstance(data, dict) else {}
    return {
        "status": str(payload.get("status", "unknown")),
        "summary": {
            "total": int(summary.get("total", 0) or 0),
            "ok": int(summary.get("ok", 0) or 0),
            "stale": int(summary.get("stale", 0) or 0),
            "failed": int(summary.get("failed", 0) or 0),
            "unknown": int(summary.get("unknown", 0) or 0),
            "exempt": int(summary.get("exempt", 0) or 0),
        },
        "stale_labels": data.get("stale_labels", []) if isinstance(data, dict) else [],
        "failed_labels": data.get("failed_labels", []) if isinstance(data, dict) else [],
        "unknown_labels": data.get("unknown_labels", []) if isinstance(data, dict) else [],
    }


def collect_friction_queue_status() -> dict[str, Any]:
    script = ROOT / "ops/plugins/lifecycle/bin/friction-queue-status"
    if not script.exists():
        return {
            "status": "unknown",
            "summary": {"total": 0, "queued": 0, "stale": 0, "filed": 0, "matched": 0, "invalid_time": 0, "dedupe_rate": 0.0},
        }

    _, payload = parse_json_output(script, ["--json"])
    summary = payload.get("summary", {}) if isinstance(payload, dict) else {}
    stale = int(summary.get("stale", 0) or 0)
    queued = int(summary.get("queued", 0) or 0)
    status = "ok"
    if stale > 0:
        status = "error"
    elif queued > 0:
        status = "warn"

    return {
        "status": status,
        "summary": {
            "total": int(summary.get("total", 0) or 0),
            "queued": queued,
            "stale": stale,
            "filed": int(summary.get("filed", 0) or 0),
            "matched": int(summary.get("matched", 0) or 0),
            "invalid_time": int(summary.get("invalid_time", 0) or 0),
            "dedupe_rate": float(summary.get("dedupe_rate", 0.0) or 0.0),
        },
    }


def collect_media_capacity_runway() -> dict[str, Any]:
    policy = load_yaml(ROOT / "ops/bindings/infra.capacity.guard.policy.yaml", {})
    runway_cfg = policy.get("runway", {}) if isinstance(policy, dict) else {}
    snapshot_rel = str(runway_cfg.get("snapshot_path", "ops/bindings/media.capacity.snapshot.yaml"))
    ttl_hours = int(runway_cfg.get("projection_freshness_ttl_hours", 30) or 30)

    snapshot_path = Path(snapshot_rel)
    if not snapshot_path.is_absolute():
        snapshot_path = ROOT / snapshot_rel

    if not snapshot_path.exists():
        return {
            "status": "unknown",
            "snapshot_present": False,
            "snapshot_path": str(snapshot_path),
            "reason": "snapshot_missing",
            "usage_pct": None,
            "days_to_fail": None,
            "policy_compliant": None,
            "age_hours": None,
        }

    payload = load_yaml(snapshot_path, {})
    if not isinstance(payload, dict):
        return {
            "status": "error",
            "snapshot_present": True,
            "snapshot_path": str(snapshot_path),
            "reason": "snapshot_parse_error",
            "usage_pct": None,
            "days_to_fail": None,
            "policy_compliant": None,
            "age_hours": None,
        }

    generated_at = str(payload.get("generated_at_utc", ""))
    age_hours = None
    if generated_at:
        try:
            ts = generated_at[:-1] + "+00:00" if generated_at.endswith("Z") else generated_at
            gen_dt = dt.datetime.fromisoformat(ts)
            if gen_dt.tzinfo is None:
                gen_dt = gen_dt.replace(tzinfo=dt.timezone.utc)
            age_hours = round((dt.datetime.now(dt.timezone.utc) - gen_dt.astimezone(dt.timezone.utc)).total_seconds() / 3600.0, 2)
        except ValueError:
            age_hours = None

    runway_status = str(payload.get("runway_status", "unknown"))
    policy_eval = payload.get("policy_evaluation", {}) if isinstance(payload.get("policy_evaluation"), dict) else {}
    projection = payload.get("projection", {}) if isinstance(payload.get("projection"), dict) else {}
    pool = payload.get("pool", {}) if isinstance(payload.get("pool"), dict) else {}
    policy_compliant = policy_eval.get("compliant")

    status = runway_status
    if age_hours is not None and age_hours > ttl_hours:
        status = "stale"

    return {
        "status": status,
        "snapshot_present": True,
        "snapshot_path": str(snapshot_path),
        "reason": "",
        "generated_at_utc": generated_at,
        "age_hours": age_hours,
        "ttl_hours": ttl_hours,
        "usage_pct": pool.get("usage_pct"),
        "days_to_warn": projection.get("days_to_warn"),
        "days_to_fail": projection.get("days_to_fail"),
        "policy_compliant": policy_compliant,
        "runway_min_days": policy_eval.get("runway_min_days"),
    }


def collect_tick_data(window_hours: int) -> dict[str, Any]:
    loops = collect_open_loops()
    gaps = collect_open_gaps()
    proposals = parse_proposals_summary()
    calendar = collect_calendar_status()
    alerts = collect_alert_status()
    handoffs = collect_handoff_status()
    timeline = collect_timeline(window_hours)
    graph = collect_graph_summary()
    comms_queue = collect_comms_queue_status()
    scheduler = collect_launchd_scheduler_status()
    friction = collect_friction_queue_status()
    media_capacity_runway = collect_media_capacity_runway()

    summary = {
        "open_loops": len(loops),
        "open_gaps": len(gaps),
        "pending_proposals": proposals.get("pending", 0),
        "active_alerts": alerts.get("active_alerts", 0),
        "active_incident_alerts": alerts.get("active_incident_alerts", 0),
        "alert_history_total": alerts.get("total_alerts", 0),
        "active_handoffs": handoffs.get("active", 0),
        "timeline_events": timeline.get("event_count", 0),
        "verify_failed_runs": timeline.get("verify_failed_runs", 0),
        "verify_current_failed_runs": timeline.get("verify_current_failed_runs", 0),
        "core_verify_latest_status": timeline.get("core_verify_latest_status", "unknown"),
        "graph_nodes": graph.get("node_count", 0),
        "graph_edges": graph.get("edge_count", 0),
        "comms_queue_slo_status": comms_queue.get("slo_status", "unknown"),
        "comms_queue_pending": comms_queue.get("queue_pending_count", 0),
        "comms_queue_escalations": comms_queue.get("pending_escalation_task_count", 0),
        "scheduler_status": scheduler.get("status", "unknown"),
        "scheduler_total_jobs": int(scheduler.get("summary", {}).get("total", 0)),
        "scheduler_failed_jobs": int(scheduler.get("summary", {}).get("failed", 0)),
        "scheduler_stale_jobs": int(scheduler.get("summary", {}).get("stale", 0)),
        "scheduler_unknown_jobs": int(scheduler.get("summary", {}).get("unknown", 0)),
        "scheduler_exempt_jobs": int(scheduler.get("summary", {}).get("exempt", 0)),
        "friction_status": friction.get("status", "unknown"),
        "friction_total": int(friction.get("summary", {}).get("total", 0)),
        "friction_queued": int(friction.get("summary", {}).get("queued", 0)),
        "friction_stale": int(friction.get("summary", {}).get("stale", 0)),
        "friction_filed": int(friction.get("summary", {}).get("filed", 0)),
        "friction_matched": int(friction.get("summary", {}).get("matched", 0)),
        "friction_dedupe_rate": float(friction.get("summary", {}).get("dedupe_rate", 0.0)),
        "media_capacity_runway_status": media_capacity_runway.get("status", "unknown"),
        "media_capacity_usage_pct": media_capacity_runway.get("usage_pct"),
        "media_capacity_days_to_fail": media_capacity_runway.get("days_to_fail"),
        "media_capacity_policy_compliant": media_capacity_runway.get("policy_compliant"),
    }

    status = "ok"
    if (
        alerts.get("status") == "error"
        or any(g.get("severity") == "critical" for g in gaps)
        or scheduler.get("status") == "error"
        or friction.get("status") == "error"
        or media_capacity_runway.get("status") == "critical"
    ):
        status = "error"
    elif (
        summary["open_loops"] > 0
        or summary["open_gaps"] > 0
        or summary["pending_proposals"] > 0
        or alerts.get("status") == "warn"
        or summary["verify_current_failed_runs"] > 0
        or str(calendar.get("status", "")).lower() in {"warn", "error"}
        or comms_queue.get("slo_status") == "incident"
        or scheduler.get("status") == "warn"
        or friction.get("status") == "warn"
        or media_capacity_runway.get("status") in {"warn", "stale", "unknown"}
        or media_capacity_runway.get("policy_compliant") is False
    ):
        status = "warn"

    return {
        "capability": "spine.control.tick",
        "schema_version": SCHEMA_VERSION,
        "generated_at": utc_now(),
        "status": status,
        "data": {
            "window_hours": window_hours,
            "summary": summary,
            "loops": loops,
            "gaps": gaps,
            "proposals": proposals,
            "calendar": calendar,
            "alerts": alerts,
            "handoffs": handoffs,
            "timeline": timeline,
            "graph": graph,
            "comms_queue": comms_queue,
            "scheduler": scheduler,
            "friction": friction,
            "media_capacity_runway": media_capacity_runway,
        },
    }


def derive_route_hint(loops: list[dict[str, Any]], gaps: list[dict[str, Any]]) -> tuple[str, str]:
    corpus_parts: list[str] = []
    for row in gaps:
        corpus_parts.extend([str(row.get("description", "")), str(row.get("parent_loop", "")), str(row.get("doc", ""))])
    for row in loops:
        corpus_parts.extend([str(row.get("objective", "")), str(row.get("loop_id", ""))])
    corpus = " ".join(corpus_parts).lower()

    matchers: list[tuple[str, str, str]] = [
        ("finance", r"\bfinance|firefly|paperless|tax|budget|transaction\b", "keyword"),
        ("identity", r"\bidentity|email|calendar|graph|outlook|office 365\b", "keyword"),
        ("automation", r"\bautomation|workflow|n8n|webhook|cron\b", "keyword"),
        ("home-automation", r"\bhome assistant|hass|zigbee|z-wave|smart-home\b", "keyword"),
        ("photos", r"\bimmich|photo|asset|album\b", "keyword"),
        ("mint", r"\bmint|artwork|quote|intake|pricing|shipping|suppliers\b", "keyword"),
        ("media", r"\bmedia|jellyfin|radarr|sonarr|sabnzbd|navidrome\b", "keyword"),
    ]
    for route_input, pattern, basis in matchers:
        if re.search(pattern, corpus):
            return route_input, basis
    # Deterministic fallback keeps route_resolve operable for delegated path testing.
    return "automation", "fallback"


def build_plan_payload(tick_payload: dict[str, Any]) -> dict[str, Any]:
    data = tick_payload.get("data", {})
    summary = data.get("summary", {})
    loops = data.get("loops", [])
    gaps = data.get("gaps", [])
    alerts = data.get("alerts", {})
    proposals = data.get("proposals", {})
    timeline = data.get("timeline", {})

    actions: list[dict[str, Any]] = []

    def add_action(
        *,
        action_id: str,
        priority: str,
        title: str,
        reason: str,
        route_target: dict[str, Any],
    ) -> None:
        actions.append(
            {
                "action_id": action_id,
                "priority": priority,
                "title": title,
                "reason": reason,
                "route_target": route_target,
                "execution_mode": "automated" if route_target.get("type") == "capability" else "delegated",
            }
        )

    if summary.get("open_gaps", 0) > 0:
        add_action(
            action_id="A01-loop-gap-verify",
            priority="P0",
            title="Run loop/gap verify pack",
            reason=f"{summary.get('open_gaps', 0)} open gap(s) detected.",
            route_target={"type": "capability", "capability": "verify.pack.run", "args": ["loop_gap"]},
        )

    for idx, loop in enumerate(loops[:3], start=1):
        loop_id = loop.get("loop_id", "")
        add_action(
            action_id=f"A1{idx}-loop-progress-{loop_id.lower()}",
            priority="P1",
            title=f"Inspect loop progress: {loop_id}",
            reason=f"Loop is {loop.get('status', 'active')} and still open.",
            route_target={"type": "capability", "capability": "loops.progress", "args": [loop_id]},
        )

    if proposals.get("pending", 0) > 0:
        add_action(
            action_id="A20-proposal-queue-health",
            priority="P1",
            title="Review proposal queue health",
            reason=f"{proposals.get('pending', 0)} pending proposal(s) require operator attention.",
            route_target={"type": "capability", "capability": "proposals.status", "args": []},
        )

    if alerts.get("total_alerts", 0) > 0:
        add_action(
            action_id="A30-stability-snapshot",
            priority="P0",
            title="Capture stability control snapshot",
            reason=f"{alerts.get('total_alerts', 0)} active alert event(s) present.",
            route_target={"type": "capability", "capability": "stability.control.snapshot", "args": []},
        )

    if bool(timeline.get("core_verify_needs_attention", False)):
        created_at = str(timeline.get("core_verify_latest_created_at", "")).strip()
        when = f" at {created_at}" if created_at else ""
        add_action(
            action_id="A40-core-verify-rerun",
            priority="P1",
            title="Re-run core verify lane",
            reason=f"Latest verify.core.run status is failed{when}.",
            route_target={"type": "capability", "capability": "verify.core.run", "args": []},
        )

    route_input, route_basis = derive_route_hint(loops, gaps)
    add_action(
        action_id="A90-route-discovery",
        priority="P2",
        title="Resolve delegation target for next work item",
        reason=f"Deterministic route lookup for agent-tool handoff (basis: {route_basis}).",
        route_target={"type": "agent_tool", "tool": "route_resolve", "input": route_input},
    )

    if not actions:
        add_action(
            action_id="A99-core-health",
            priority="P2",
            title="Run core verify lane",
            reason="No urgent signals detected; maintain baseline health.",
            route_target={"type": "capability", "capability": "verify.core.run", "args": []},
        )

    priority_order = {"P0": 0, "P1": 1, "P2": 2}
    actions.sort(key=lambda row: (priority_order.get(row.get("priority", "P2"), 9), row.get("action_id", "")))

    return {
        "capability": "spine.control.plan",
        "schema_version": SCHEMA_VERSION,
        "generated_at": utc_now(),
        "status": "ok",
        "data": {
            "summary": summary,
            "signals": {
                "open_loop_ids": [l.get("loop_id", "") for l in loops],
                "open_gap_ids": [g.get("id", "") for g in gaps],
                "alerts": alerts.get("active_domains", []),
            },
            "actions": actions,
            "recommended_action_ids": [a.get("action_id", "") for a in actions[:3]],
        },
    }


def load_capability_approval_index() -> dict[str, str]:
    caps = load_yaml(ROOT / "ops/capabilities.yaml", {}).get("capabilities", {})
    index: dict[str, str] = {}
    if isinstance(caps, dict):
        for capability, body in caps.items():
            approval = "auto"
            if isinstance(body, dict):
                approval = str(body.get("approval", "auto"))
            index[str(capability)] = approval
    return index


def extract_run_key(text: str) -> str:
    m = re.search(r"Run Key:\s+([^\s]+)", text)
    return m.group(1) if m else ""


def extract_receipt_path(text: str) -> str:
    m = re.search(r"Receipt:\s+([^\s]+)", text)
    return m.group(1) if m else ""


def write_control_artifact(payload: dict[str, Any]) -> dict[str, str]:
    runtime = resolve_runtime_paths()
    out_dir = runtime["outbox"] / "operations"
    out_dir.mkdir(parents=True, exist_ok=True)

    json_path = out_dir / "control-plane-latest.json"
    md_path = out_dir / "control-plane-latest.md"

    json_path.write_text(json.dumps(payload, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    results = payload.get("data", {}).get("results", [])
    lines = [
        "# Control Plane Latest",
        "",
        f"- Generated: {payload.get('generated_at', '')}",
        f"- Status: {payload.get('status', '')}",
        "",
        "## Executed Actions",
        "",
    ]
    if not results:
        lines.append("- None")
    else:
        for row in results:
            lines.extend(
                [
                    f"### {row.get('action_id', '')}",
                    f"- Status: {row.get('status', '')}",
                    f"- Route: {row.get('route_target', {}).get('type', '')}",
                    f"- Capability: {row.get('route_target', {}).get('capability', '')}",
                    f"- Run Key: {row.get('run_key', '')}",
                    f"- Receipt: {row.get('receipt_path', '')}",
                    "",
                ]
            )
    md_path.write_text("\n".join(lines).strip() + "\n", encoding="utf-8")

    return {"json": str(json_path), "markdown": str(md_path)}


def priority_rank(priority: str) -> int:
    return {"P0": 0, "P1": 1, "P2": 2}.get((priority or "").strip().upper(), 9)


def generate_task_id() -> str:
    ts = dt.datetime.now(dt.timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    rand = os.urandom(2).hex()
    return f"TASK-{ts}-{rand}"


def resolve_route_target_agent(route_target: dict[str, Any]) -> tuple[bool, dict[str, Any]]:
    tool = str(route_target.get("tool", "")).strip()
    route_input = str(route_target.get("input", "")).strip()
    if tool != "route_resolve":
        return False, {"error_code": "unsupported_agent_tool", "message": f"unsupported agent_tool: {tool}"}
    if not route_input:
        return False, {"error_code": "route_input_required", "message": "route_resolve input is required"}

    route_script = ROOT / "ops/plugins/agent/bin/agent-route"
    if not route_script.exists():
        return False, {"error_code": "route_script_missing", "message": f"missing script: {route_script}"}

    rc, out, err = run_cmd([str(route_script), "--json", route_input], cwd=ROOT)
    if rc != 0:
        return False, {"error_code": "route_resolution_failed", "message": (err.strip() or out.strip() or "route resolution failed")}
    try:
        payload = json.loads(out.strip())
    except json.JSONDecodeError:
        return False, {"error_code": "route_invalid_json", "message": "agent.route --json returned invalid JSON"}

    if str(payload.get("status", "")) != "matched":
        return False, {"error_code": "route_not_found", "message": f"no route match for input: {route_input}", "route_payload": payload}

    agent = payload.get("data", {}).get("agent", {})
    agent_id = str(agent.get("id", "")).strip()
    if not agent_id:
        return False, {"error_code": "route_missing_agent", "message": "matched route payload missing data.agent.id", "route_payload": payload}

    return True, {
        "route_payload": payload,
        "agent_id": agent_id,
    }


def run_agent_health_preflight(agent_id: str, *, strict_agent_health: bool) -> tuple[bool, dict[str, Any]]:
    health_script = ROOT / "ops/plugins/agent/bin/agent-health-check-all"
    if not health_script.exists():
        return False, {"error_code": "health_script_missing", "message": f"missing script: {health_script}"}

    cmd = [str(health_script), "--agents", agent_id, "--json"]
    if strict_agent_health:
        cmd.append("--strict")
    rc, out, err = run_cmd(cmd, cwd=ROOT)
    text = out.strip() or err.strip()
    try:
        payload = json.loads(text) if text else {}
    except json.JSONDecodeError:
        payload = {"status": "error", "error": {"message": text or "invalid health preflight payload"}}

    if strict_agent_health and rc != 0:
        return False, {"error_code": "agent_health_preflight_failed", "message": "strict agent health preflight failed", "health": payload}
    return True, {"health": payload}


def run_capability_action(capability: str, args: list[str], *, confirm: bool, dry_run: bool) -> dict[str, Any]:
    cmd = [str(ROOT / "bin/ops"), "cap", "run", capability] + args
    if dry_run:
        return {"status": "dry_run", "command": cmd, "run_key": "", "receipt_path": ""}

    input_text = "yes\n" if confirm else None
    rc, out, err = run_cmd(cmd, cwd=ROOT, input_text=input_text)
    combined = (out or "") + ("\n" + err if err else "")
    return {
        "status": "done" if rc == 0 else "failed",
        "exit_code": rc,
        "command": cmd,
        "run_key": extract_run_key(combined),
        "receipt_path": extract_receipt_path(combined),
        "output_snippet": "\n".join(combined.strip().splitlines()[-20:]),
    }


def enqueue_delegated_agent_task(
    *,
    action_id: str,
    action: dict[str, Any],
    route_target: dict[str, Any],
    dry_run: bool,
    strict_agent_health: bool,
) -> dict[str, Any]:
    ok, route_data = resolve_route_target_agent(route_target)
    if not ok:
        result = {"action_id": action_id, "status": "error", **route_data, "route_target": route_target}
        return result

    agent_id = route_data["agent_id"]
    ok_health, health_data = run_agent_health_preflight(agent_id, strict_agent_health=strict_agent_health)
    if not ok_health:
        result = {
            "action_id": action_id,
            "status": "error",
            **health_data,
            "route_target": route_target,
            "route_resolution": route_data.get("route_payload", {}),
            "required_agents": [agent_id],
        }
        return result

    task_id = generate_task_id()
    payload_obj = {
        "action_id": action_id,
        "title": action.get("title", ""),
        "reason": action.get("reason", ""),
        "route_target": route_target,
        "execution_mode": "delegated",
        "route_resolution": route_data.get("route_payload", {}),
    }
    payload_json = json.dumps(payload_obj, separators=(",", ":"))
    summary = f"{action_id}: {action.get('title', 'delegated action')}"
    cmd_args = [
        "mailroom.task.enqueue",
        "--task-id",
        task_id,
        "--summary",
        summary,
        "--required-agents",
        agent_id,
        "--route-target",
        "agent_tool",
        "--payload",
        payload_json,
        "--json",
    ]
    if dry_run:
        cmd_args.append("--dry-run")

    run_data = run_capability_action("mailroom.task.enqueue", cmd_args[1:], confirm=False, dry_run=False)  # run through governed cap
    run_data["command"] = [str(ROOT / "bin/ops"), "cap", "run"] + cmd_args
    run_data["task_id"] = task_id
    run_data["route_target"] = route_target
    run_data["required_agents"] = [agent_id]
    run_data["route_resolution"] = route_data.get("route_payload", {})
    run_data["health_preflight"] = health_data.get("health", {})
    run_data["action_id"] = action_id
    if dry_run and run_data.get("status") == "done":
        # Preserve dry-run semantics while still providing deterministic task ID.
        run_data["status"] = "delegated_dry_run"
    elif run_data.get("status") == "done":
        run_data["status"] = "delegated_queued"
    else:
        run_data["status"] = "failed"
    return run_data


def execute_plan_actions(
    action_ids: list[str],
    *,
    confirm: bool,
    dry_run: bool,
    window_hours: int,
    allow_agent_tools: bool,
    strict_agent_health: bool,
    skip_manual_without_confirm: bool = False,
) -> tuple[dict[str, Any], int]:
    tick_payload = collect_tick_data(window_hours)
    plan_payload = build_plan_payload(tick_payload)
    actions = plan_payload.get("data", {}).get("actions", [])
    action_index = {a.get("action_id", ""): a for a in actions}
    approvals = load_capability_approval_index()

    results: list[dict[str, Any]] = []
    fail_count = 0

    if not action_ids:
        return (
            {
                "capability": "spine.control.execute",
                "schema_version": SCHEMA_VERSION,
                "generated_at": utc_now(),
                "status": "error",
                "error": {"message": "at least one --action-id is required"},
            },
            1,
        )

    for action_id in action_ids:
        action = action_index.get(action_id)
        if not action:
            fail_count += 1
            results.append(
                {
                    "action_id": action_id,
                    "status": "error",
                    "error_code": "action_not_found",
                    "message": "action_id not present in latest plan output",
                }
            )
            continue

        route = action.get("route_target", {})
        route_type = str(route.get("type", "")).strip()
        if route_type == "capability":
            capability = str(route.get("capability", "")).strip()
            args = [str(x) for x in route.get("args", [])]
            approval = approvals.get(capability, "auto")

            if approval == "manual" and not confirm:
                row = {
                    "action_id": action_id,
                    "status": "skipped_manual",
                    "error_code": "manual_confirmation_required",
                    "message": f"capability '{capability}' requires --confirm",
                    "route_target": route,
                }
                if skip_manual_without_confirm:
                    results.append(row)
                    continue
                fail_count += 1
                row["status"] = "error"
                results.append(row)
                continue

            run_data = run_capability_action(capability, args, confirm=(approval == "manual" and confirm), dry_run=dry_run)
            row = {
                "action_id": action_id,
                "route_target": route,
                **run_data,
            }
            if row.get("status") in {"failed", "error"}:
                fail_count += 1
            results.append(row)
            continue

        if route_type == "agent_tool":
            if not allow_agent_tools:
                fail_count += 1
                results.append(
                    {
                        "action_id": action_id,
                        "status": "error",
                        "error_code": "agent_tool_execution_disabled",
                        "message": "agent_tool route targets are disabled for this execution",
                        "route_target": route,
                    }
                )
                continue

            row = enqueue_delegated_agent_task(
                action_id=action_id,
                action=action,
                route_target=route,
                dry_run=dry_run,
                strict_agent_health=strict_agent_health,
            )
            if row.get("status") in {"failed", "error"}:
                fail_count += 1
            results.append(row)
            continue

        fail_count += 1
        results.append(
            {
                "action_id": action_id,
                "status": "error",
                "error_code": "unsupported_route_type",
                "message": f"unsupported route target type: {route_type}",
                "route_target": route,
            }
        )

    status = "ok" if fail_count == 0 else "error"
    payload = {
        "capability": "spine.control.execute",
        "schema_version": SCHEMA_VERSION,
        "generated_at": utc_now(),
        "status": status,
        "data": {
            "selected_action_ids": action_ids,
            "dry_run": dry_run,
            "confirm": confirm,
            "allow_agent_tools": allow_agent_tools,
            "strict_agent_health": strict_agent_health,
            "tick_summary": tick_payload.get("data", {}).get("summary", {}),
            "plan_generated_at": plan_payload.get("generated_at", ""),
            "results": results,
        },
    }
    payload["data"]["artifacts"] = write_control_artifact(payload)
    return payload, 0 if fail_count == 0 else 1


def run_control_cycle(
    *,
    window_hours: int,
    max_actions: int,
    max_priority: str,
    confirm_manual: bool,
    allow_agent_tools: bool,
    allow_unhealthy_agents: bool,
    dry_run: bool,
) -> tuple[dict[str, Any], int]:
    tick_payload = collect_tick_data(window_hours)
    plan_payload = build_plan_payload(tick_payload)
    actions = plan_payload.get("data", {}).get("actions", [])
    max_priority_rank = priority_rank(max_priority)

    selected = [
        row.get("action_id", "")
        for row in actions
        if priority_rank(str(row.get("priority", ""))) <= max_priority_rank
    ]
    selected = [x for x in selected if x][: max(1, max_actions)]

    if not selected:
        payload = {
            "capability": "spine.control.cycle",
            "schema_version": SCHEMA_VERSION,
            "generated_at": utc_now(),
            "status": "ok",
            "data": {
                "window_hours": window_hours,
                "max_actions": max_actions,
                "max_priority": max_priority,
                "dry_run": dry_run,
                "selected_action_ids": [],
                "tick_summary": tick_payload.get("data", {}).get("summary", {}),
                "plan_generated_at": plan_payload.get("generated_at", ""),
                "results": [],
                "message": "no eligible actions for cycle selection",
            },
        }
        payload["data"]["artifacts"] = write_control_artifact(payload)
        return payload, 0

    exec_payload, rc = execute_plan_actions(
        selected,
        confirm=confirm_manual,
        dry_run=dry_run,
        window_hours=window_hours,
        allow_agent_tools=allow_agent_tools,
        strict_agent_health=not allow_unhealthy_agents,
        skip_manual_without_confirm=True,
    )

    payload = {
        "capability": "spine.control.cycle",
        "schema_version": SCHEMA_VERSION,
        "generated_at": utc_now(),
        "status": exec_payload.get("status", "error"),
        "data": {
            "window_hours": window_hours,
            "max_actions": max_actions,
            "max_priority": max_priority,
            "dry_run": dry_run,
            "confirm_manual": confirm_manual,
            "allow_agent_tools": allow_agent_tools,
            "allow_unhealthy_agents": allow_unhealthy_agents,
            "selected_action_ids": selected,
            "tick_summary": tick_payload.get("data", {}).get("summary", {}),
            "plan_generated_at": plan_payload.get("generated_at", ""),
            "results": exec_payload.get("data", {}).get("results", []),
            "artifacts": exec_payload.get("data", {}).get("artifacts", {}),
        },
    }
    return payload, rc


def render_tick_markdown(payload: dict[str, Any]) -> str:
    data = payload.get("data", {})
    summary = data.get("summary", {})
    lines = [
        "# Spine Control Tick",
        "",
        f"- Generated: {payload.get('generated_at', '')}",
        f"- Status: {payload.get('status', '')}",
        f"- Open Loops: {summary.get('open_loops', 0)}",
        f"- Open Gaps: {summary.get('open_gaps', 0)}",
        f"- Pending Proposals: {summary.get('pending_proposals', 0)}",
        f"- Active Alerts: {summary.get('active_alerts', 0)}",
        f"- Active Handoffs: {summary.get('active_handoffs', 0)}",
        f"- Verify Failed Runs ({data.get('window_hours', 24)}h, historical): {summary.get('verify_failed_runs', 0)}",
        f"- Verify Current Failed Runs: {summary.get('verify_current_failed_runs', 0)}",
        f"- Core Verify Latest Status: {summary.get('core_verify_latest_status', 'unknown')}",
        f"- Graph Nodes: {summary.get('graph_nodes', 0)}",
        f"- Graph Edges: {summary.get('graph_edges', 0)}",
        f"- Media Capacity Runway: {summary.get('media_capacity_runway_status', 'unknown')} (usage={summary.get('media_capacity_usage_pct', 'n/a')}% days_to_fail={summary.get('media_capacity_days_to_fail', 'n/a')} compliant={summary.get('media_capacity_policy_compliant', 'n/a')})",
        f"- CommsQueue: {summary.get('comms_queue_slo_status', 'unknown')} (pending={summary.get('comms_queue_pending', 0)} escalations={summary.get('comms_queue_escalations', 0)})",
        f"- FrictionQueue: {summary.get('friction_status', 'unknown')} (queued={summary.get('friction_queued', 0)} stale={summary.get('friction_stale', 0)} filed={summary.get('friction_filed', 0)} matched={summary.get('friction_matched', 0)} dedupe_rate={summary.get('friction_dedupe_rate', 0.0)})",
        "",
    ]
    loops = data.get("loops", [])
    if loops:
        lines.append("## Open Loops")
        lines.append("")
        for row in loops:
            lines.append(f"- {row.get('loop_id', '')} ({row.get('status', '')})")
        lines.append("")
    gaps = data.get("gaps", [])
    if gaps:
        lines.append("## Open Gaps")
        lines.append("")
        for row in gaps:
            lines.append(f"- {row.get('id', '')} [{row.get('severity', '')}]")
    return "\n".join(lines).strip() + "\n"


def render_plan_markdown(payload: dict[str, Any]) -> str:
    data = payload.get("data", {})
    lines = [
        "# Spine Control Plan",
        "",
        f"- Generated: {payload.get('generated_at', '')}",
        f"- Recommended: {', '.join(data.get('recommended_action_ids', [])) or '(none)'}",
        "",
        "## Actions",
        "",
    ]
    for row in data.get("actions", []):
        route = row.get("route_target", {})
        route_kind = route.get("type", "")
        if route_kind == "capability":
            route_label = f"{route.get('capability', '')} {' '.join(route.get('args', []))}".strip()
        else:
            route_label = f"{route.get('tool', '')} input={route.get('input', '')}".strip()
        lines.extend(
            [
                f"### {row.get('action_id', '')} [{row.get('priority', '')}]",
                f"- Title: {row.get('title', '')}",
                f"- Reason: {row.get('reason', '')}",
                f"- Route: {route_kind}",
                f"- Target: {route_label}",
                "",
            ]
        )
    return "\n".join(lines).strip() + "\n"


def render_execute_markdown(payload: dict[str, Any]) -> str:
    data = payload.get("data", {})
    lines = [
        "# Spine Control Execute",
        "",
        f"- Generated: {payload.get('generated_at', '')}",
        f"- Status: {payload.get('status', '')}",
        "",
        "## Results",
        "",
    ]
    for row in data.get("results", []):
        lines.extend(
            [
                f"### {row.get('action_id', '')}",
                f"- Status: {row.get('status', '')}",
                f"- Run Key: {row.get('run_key', '')}",
                f"- Receipt: {row.get('receipt_path', '')}",
                "",
            ]
        )
    artifacts = data.get("artifacts", {})
    if artifacts:
        lines.extend(
            [
                "## Artifacts",
                "",
                f"- JSON: {artifacts.get('json', '')}",
                f"- Markdown: {artifacts.get('markdown', '')}",
            ]
        )
    return "\n".join(lines).strip() + "\n"


def render_cycle_markdown(payload: dict[str, Any]) -> str:
    data = payload.get("data", {})
    lines = [
        "# Spine Control Cycle",
        "",
        f"- Generated: {payload.get('generated_at', '')}",
        f"- Status: {payload.get('status', '')}",
        f"- Dry Run: {data.get('dry_run', False)}",
        f"- Max Priority: {data.get('max_priority', '')}",
        f"- Selected Actions: {', '.join(data.get('selected_action_ids', [])) or '(none)'}",
        "",
        "## Results",
        "",
    ]
    for row in data.get("results", []):
        lines.extend(
            [
                f"### {row.get('action_id', '')}",
                f"- Status: {row.get('status', '')}",
                f"- Run Key: {row.get('run_key', '')}",
                f"- Task ID: {row.get('task_id', '')}",
                "",
            ]
        )
    return "\n".join(lines).strip() + "\n"


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Unified spine control loop surfaces")
    sub = parser.add_subparsers(dest="command", required=True)

    tick = sub.add_parser("tick", help="Aggregate control-plane signals")
    tick.add_argument("--window-hours", type=int, default=24)
    tick.add_argument("--json", action="store_true")

    plan = sub.add_parser("plan", help="Build prioritized next-action plan")
    plan.add_argument("--window-hours", type=int, default=24)
    plan.add_argument("--json", action="store_true")

    execute = sub.add_parser("execute", help="Execute approved plan actions")
    execute.add_argument("--action-id", action="append", default=[])
    execute.add_argument("--confirm", action="store_true", help="Allow manual approval capabilities")
    execute.add_argument("--allow-agent-tools", action="store_true", help="Allow agent_tool routes by enqueuing governed mailroom tasks")
    execute.add_argument("--allow-unhealthy-agents", action="store_true", help="Bypass strict agent health preflight for delegated tasks")
    execute.add_argument("--dry-run", action="store_true")
    execute.add_argument("--window-hours", type=int, default=24)
    execute.add_argument("--json", action="store_true")

    cycle = sub.add_parser("cycle", help="Run autonomous observe-plan-act cycle with governed execution/delegation")
    cycle.add_argument("--window-hours", type=int, default=24)
    cycle.add_argument("--max-actions", type=int, default=3)
    cycle.add_argument("--max-priority", choices=["P0", "P1", "P2"], default="P1")
    cycle.add_argument("--confirm-manual", action="store_true", help="Allow manual capabilities during cycle execution")
    cycle.add_argument("--no-agent-tools", action="store_true", help="Disable agent_tool delegation for this cycle")
    cycle.add_argument("--allow-unhealthy-agents", action="store_true", help="Bypass strict agent health preflight for delegated tasks")
    cycle.add_argument("--dry-run", action="store_true")
    cycle.add_argument("--json", action="store_true")

    return parser


def main() -> int:
    args = build_parser().parse_args()

    if args.command == "tick":
        payload = collect_tick_data(args.window_hours)
        if args.json:
            print(json.dumps(payload, indent=2))
        else:
            print(render_tick_markdown(payload), end="")
        return 0

    if args.command == "plan":
        payload = build_plan_payload(collect_tick_data(args.window_hours))
        if args.json:
            print(json.dumps(payload, indent=2))
        else:
            print(render_plan_markdown(payload), end="")
        return 0

    if args.command == "execute":
        payload, rc = execute_plan_actions(
            args.action_id,
            confirm=bool(args.confirm),
            dry_run=bool(args.dry_run),
            window_hours=args.window_hours,
            allow_agent_tools=bool(args.allow_agent_tools),
            strict_agent_health=not bool(args.allow_unhealthy_agents),
        )
        if args.json:
            print(json.dumps(payload, indent=2))
        else:
            print(render_execute_markdown(payload), end="")
        return rc

    if args.command == "cycle":
        payload, rc = run_control_cycle(
            window_hours=args.window_hours,
            max_actions=max(1, int(args.max_actions)),
            max_priority=args.max_priority,
            confirm_manual=bool(args.confirm_manual),
            allow_agent_tools=not bool(args.no_agent_tools),
            allow_unhealthy_agents=bool(args.allow_unhealthy_agents),
            dry_run=bool(args.dry_run),
        )
        if args.json:
            print(json.dumps(payload, indent=2))
        else:
            print(render_cycle_markdown(payload), end="")
        return rc

    return 1


if __name__ == "__main__":
    sys.exit(main())
