#!/usr/bin/env python3
"""
mailroom.bridge.serve - minimal HTTP bridge to the spine mailroom.

Contract:
- Reads from canonical runtime root (SPINE_REPO).
- Writes prompts via ops/runtime/inbox/agent-enqueue.sh (mailroom/inbox/queued).
- Token auth enforced by binding (`auth.require_token` + `auth.token_env`).
"""

from __future__ import annotations

import json
import os
import subprocess
import sys
import time
import shutil
from http import HTTPStatus
from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
from pathlib import Path
from typing import Any
from urllib.parse import parse_qs, urlparse


def _now_iso() -> str:
    # Use local time string only for diagnostics; do not treat as SSOT.
    return time.strftime("%Y-%m-%dT%H:%M:%S%z")


def _stop(msg: str, code: int = 2) -> None:
    print(f"STOP: {msg}", file=sys.stderr)
    raise SystemExit(code)


def _sh(*args: str) -> str:
    p = subprocess.run(list(args), capture_output=True, text=True)
    if p.returncode != 0:
        raise RuntimeError(p.stderr.strip() or p.stdout.strip() or f"command failed: {' '.join(args)}")
    return p.stdout.strip()


def _yq(binding: Path, expr: str, default: str) -> str:
    try:
        out = _sh("yq", "-r", expr, str(binding))
    except Exception:
        return default
    if out in ("", "null"):
        return default
    return out


def _safe_child(root: Path, rel: str) -> Path:
    # Prevent path traversal.
    rel = rel.lstrip("/")
    p = (root / rel).resolve()
    root_r = root.resolve()
    if p == root_r:
        return p
    if root_r not in p.parents:
        raise ValueError("path escapes root")
    return p


def _read_limited(path: Path, max_bytes: int) -> bytes:
    size = path.stat().st_size
    if size > max_bytes:
        raise ValueError(f"file too large ({size} bytes > max {max_bytes})")
    return path.read_bytes()


def _parse_scope_frontmatter(md: str) -> tuple[dict[str, str], int]:
    """
    Parse a small YAML frontmatter block from a loop scope markdown file.

    We intentionally avoid PyYAML here; loop scope frontmatter is simple
    key: value pairs and that's all we need for the bridge.
    """

    lines = md.splitlines()
    if not lines or lines[0].strip() != "---":
        return {}, 0

    fm: dict[str, str] = {}
    i = 1
    while i < len(lines):
        line = lines[i].rstrip("\n")
        if line.strip() == "---":
            return fm, i + 1
        s = line.strip()
        if not s or s.startswith("#") or ":" not in s:
            i += 1
            continue
        k, v = s.split(":", 1)
        fm[k.strip()] = v.strip().strip('"')
        i += 1
    return {}, 0


def _scope_title(md: str, body_start_line: int) -> str:
    lines = md.splitlines()
    for raw in lines[body_start_line:]:
        s = raw.strip()
        if not s.startswith("#"):
            continue
        # First markdown heading after frontmatter wins.
        title = s.lstrip("#").strip()
        if title.lower().startswith("loop scope:"):
            title = title[len("loop scope:") :].strip()
        return title
    return ""


def _is_open_status(status: str) -> bool:
    return (status or "").strip().lower() in {"active", "draft", "open"}


def _is_output_delim(line: str) -> bool:
    s = (line or "").strip()
    if len(s) < 8:
        return False
    return all(ch in {"─", "-"} for ch in s)


def _reduce_open_loops_from_scopes(scopes_dir: Path) -> list[dict[str, Any]]:
    """
    Reduce open loops from scope files (mailroom/state/loop-scopes/*.scope.md).

    This matches ops/commands/loops.sh semantics:
    - status in {active,draft,open} = open
    - status == closed = closed
    - skip non-loop scope files (e.g. status: authoritative)
    """

    if not scopes_dir.exists() or not scopes_dir.is_dir():
        return []

    loops: list[dict[str, Any]] = []
    for scope_file in sorted(scopes_dir.glob("*.scope.md")):
        try:
            md = scope_file.read_text(encoding="utf-8", errors="replace")
        except OSError:
            continue

        fm, body_start = _parse_scope_frontmatter(md)
        loop_id = (fm.get("loop_id") or "").strip()
        if not loop_id:
            continue

        status = (fm.get("status") or "").strip().lower() or "unknown"
        severity = (fm.get("severity") or "").strip() or "-"
        owner = (fm.get("owner") or "").strip() or "unassigned"

        # Skip non-loop scope files (e.g. status: authoritative).
        if status not in {"active", "draft", "open", "closed"}:
            continue
        if not _is_open_status(status):
            continue

        title = _scope_title(md, body_start) or loop_id
        display_title = title if title != loop_id else ""

        loops.append(
            {
                "loop_id": loop_id,
                "status": status,
                "severity": severity,
                "owner": owner,
                "title": display_title,
            }
        )

    return loops


class Handler(BaseHTTPRequestHandler):
    server_version = "spine-mailroom-bridge/0.1"

    # Set on server startup.
    config: dict[str, Any] = {}

    def _json(self, status: int, obj: Any) -> None:
        body = json.dumps(obj, indent=2, sort_keys=True).encode("utf-8")
        self.send_response(status)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.send_header("Content-Length", str(len(body)))
        self.end_headers()
        self.wfile.write(body)

    def _text(self, status: int, body: str, content_type: str = "text/plain; charset=utf-8") -> None:
        b = body.encode("utf-8")
        self.send_response(status)
        self.send_header("Content-Type", content_type)
        self.send_header("Content-Length", str(len(b)))
        self.end_headers()
        self.wfile.write(b)

    def _extract_request_token(self) -> str:
        """Extract the bearer or X-Spine-Token from the request."""
        hdr = self.headers.get("Authorization", "")
        if hdr.startswith("Bearer "):
            return hdr.removeprefix("Bearer ").strip()
        return (self.headers.get("X-Spine-Token", "") or "").strip()

    def _auth_ok(self) -> bool:
        primary_token = self.config.get("token") or ""
        if not primary_token:
            # Tailnet-only deployments can run without a token (explicitly documented).
            return True

        req_token = self._extract_request_token()
        if not req_token:
            return False

        # Accept primary token
        if req_token == primary_token:
            return True

        # Accept any RBAC role token
        roles = self.config.get("cap_rpc_roles") or {}
        return req_token in roles

    def _require_auth(self) -> bool:
        if self._auth_ok():
            return True
        self._json(HTTPStatus.UNAUTHORIZED, {"error": "unauthorized"})
        return False

    def _cap_rpc_role_allows(self, capability: str) -> bool:
        """Check if the request token's RBAC role allows the given capability."""
        roles = self.config.get("cap_rpc_roles") or {}
        if not roles:
            # No roles configured: any authenticated token gets full allowlist.
            return True

        req_token = self._extract_request_token()
        if req_token not in roles:
            # Token is the primary auth token but not in roles — full access.
            primary_token = self.config.get("token") or ""
            if req_token == primary_token:
                return True
            return False

        allow = roles[req_token]
        if allow == "*":
            return True
        return capability in allow

    def do_GET(self) -> None:  # noqa: N802
        parsed = urlparse(self.path)
        path = parsed.path.rstrip("/") or "/"
        qs = parse_qs(parsed.query or "")

        if path == "/health":
            token_required = bool(self.config.get("token"))
            return self._json(
                HTTPStatus.OK,
                {
                    "status": "ok",
                    "now": _now_iso(),
                    "listen": {"host": self.config.get("host"), "port": self.config.get("port")},
                    "auth": {"token_required": token_required, "token_env": self.config.get("token_env")},
                },
            )

        if not self._require_auth():
            return

        spine_repo = Path(self.config["spine_repo"])
        outbox_root = spine_repo / "mailroom/outbox"
        receipts_root = spine_repo / "receipts/sessions"
        scopes_dir = spine_repo / "mailroom/state/loop-scopes"
        max_read = int(self.config.get("max_read_bytes") or 262144)

        if path == "/loops/open":
            loops = _reduce_open_loops_from_scopes(scopes_dir)
            # Stable ordering for clients.
            severity_rank = {"critical": 0, "high": 1, "medium": 2, "low": 3}
            loops.sort(
                key=lambda r: (
                    severity_rank.get((r.get("severity") or "medium").lower(), 9),
                    r.get("owner", ""),
                    r.get("loop_id", ""),
                )
            )
            return self._json(HTTPStatus.OK, {"open_loops": loops, "count": len(loops)})

        if path == "/outbox/list":
            rel = (qs.get("path") or [""])[0]
            try:
                base = _safe_child(outbox_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not base.exists():
                return self._json(HTTPStatus.NOT_FOUND, {"error": "not found"})
            if not base.is_dir():
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "path is not a directory"})
            items = []
            for child in sorted(base.iterdir()):
                try:
                    st = child.stat()
                except FileNotFoundError:
                    continue
                items.append(
                    {
                        "path": str(child.relative_to(outbox_root)),
                        "type": "dir" if child.is_dir() else "file",
                        "size": st.st_size,
                        "mtime": int(st.st_mtime),
                    }
                )
            return self._json(HTTPStatus.OK, {"root": str(base.relative_to(outbox_root)), "items": items})

        if path == "/outbox/read":
            rel = (qs.get("path") or [""])[0]
            try:
                p = _safe_child(outbox_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not p.exists() or not p.is_file():
                return self._json(HTTPStatus.NOT_FOUND, {"error": "not found"})
            try:
                data = _read_limited(p, max_read)
            except ValueError as e:
                return self._json(HTTPStatus.REQUEST_ENTITY_TOO_LARGE, {"error": str(e)})
            # Best-effort text, fallback to bytes via latin-1.
            try:
                text = data.decode("utf-8")
                return self._text(HTTPStatus.OK, text, content_type="text/plain; charset=utf-8")
            except UnicodeDecodeError:
                return self._text(HTTPStatus.OK, data.decode("latin-1"), content_type="application/octet-stream")

        if path == "/receipts/read":
            rel = (qs.get("path") or [""])[0]
            # Allow e.g. "RCAP-.../receipt.md" or "RCAP-.../output.txt"
            try:
                p = _safe_child(receipts_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not p.exists() or not p.is_file():
                return self._json(HTTPStatus.NOT_FOUND, {"error": "not found"})
            try:
                data = _read_limited(p, max_read)
            except ValueError as e:
                return self._json(HTTPStatus.REQUEST_ENTITY_TOO_LARGE, {"error": str(e)})
            return self._text(HTTPStatus.OK, data.decode("utf-8", errors="replace"))

        return self._json(HTTPStatus.NOT_FOUND, {"error": "unknown endpoint"})

    def _handle_rag_ask(self) -> None:
        """POST /rag/ask — governed RAG query via rag.anythingllm.ask capability."""
        clen = int(self.headers.get("Content-Length", "0") or "0")
        if clen <= 0 or clen > 65536:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid content length"})

        try:
            payload = json.loads(self.rfile.read(clen).decode("utf-8"))
        except Exception:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid JSON body"})

        question = (payload.get("question") or "").strip()
        if not question:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "question is required"})

        workspace = (payload.get("workspace") or "agentic-spine").strip()
        mode = (payload.get("mode") or "auto").strip()
        if mode not in ("auto", "chat", "retrieve"):
            return self._json(HTTPStatus.BAD_REQUEST, {"error": f"invalid mode: {mode} (expected: auto, chat, retrieve)"})
        try:
            max_chars = int(payload.get("context_max_chars") or 10000)
        except (TypeError, ValueError):
            max_chars = 10000
        if max_chars < 100:
            max_chars = 100
        if max_chars > 100000:
            max_chars = 100000

        spine_repo = Path(self.config["spine_repo"])
        ops_bin = spine_repo / "bin" / "ops"
        if not ops_bin.exists():
            return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "ops binary not found"})

        # Call: ./bin/ops cap run rag.anythingllm.ask "<question>" --mode <mode> --workspace <ws>
        args = [
            str(ops_bin), "cap", "run", "rag.anythingllm.ask",
            question, "--mode", mode, "--workspace", workspace,
        ]

        env = os.environ.copy()
        env["SPINE_REPO"] = str(spine_repo)
        env["SPINE_CODE"] = str(spine_repo)

        try:
            p = subprocess.run(
                args,
                capture_output=True,
                timeout=120,
                env=env,
                cwd=str(spine_repo),
            )
        except subprocess.TimeoutExpired:
            return self._json(HTTPStatus.GATEWAY_TIMEOUT, {"error": "RAG query timed out (120s)"})

        stdout = p.stdout.decode("utf-8", errors="replace")
        stderr = p.stderr.decode("utf-8", errors="replace")

        if p.returncode != 0:
            return self._json(
                HTTPStatus.INTERNAL_SERVER_ERROR,
                {"error": "rag query failed", "stderr": stderr[:2000], "stdout": stdout[:2000]},
            )

        # Parse capability-runner output:
        # - receipt path is emitted in stdout as "Receipt: ..."
        # - useful payload must come from the final capability execution block
        #   after "== PRECONDITIONS OK ==" to avoid precondition output contamination.
        lines = stdout.splitlines()
        receipt = ""
        for raw in lines:
            s = raw.strip()
            if s.startswith("Receipt:"):
                receipt = s.split("Receipt:", 1)[1].strip()
                continue

        pre_ok_idx = -1
        for i, raw in enumerate(lines):
            if raw.strip() == "== PRECONDITIONS OK ==":
                pre_ok_idx = i

        executing_idx = -1
        for i, raw in enumerate(lines):
            if pre_ok_idx >= 0 and i <= pre_ok_idx:
                continue
            if raw.strip().lower() == "executing...":
                executing_idx = i

        start_idx = None
        for i, raw in enumerate(lines):
            if executing_idx >= 0 and i <= executing_idx:
                continue
            if _is_output_delim(raw):
                start_idx = i + 1
                break
        if start_idx is None:
            start_idx = executing_idx + 1 if executing_idx >= 0 else 0

        end_idx = len(lines)
        for i in range(start_idx, len(lines)):
            if _is_output_delim(lines[i]):
                end_idx = i
                break

        payload_lines = lines[start_idx:end_idx]
        answer_lines: list[str] = []
        sources: list[str] = []
        in_sources = False

        for line in payload_lines:
            if line.strip() == "Sources:":
                in_sources = True
                continue
            if in_sources:
                s = line.strip()
                if s.startswith("- "):
                    sources.append(s[2:])
                elif s:
                    sources.append(s)
            else:
                answer_lines.append(line)

        answer = "\n".join(answer_lines).strip()
        if not answer:
            answer = stdout.strip()

        # Prefer the capability payload starting at mode: (chat/retrieve) when preface noise exists.
        if not answer.startswith("mode:"):
            mode_pos = answer.find("mode:")
            if mode_pos >= 0:
                answer = answer[mode_pos:].strip()

        if answer.startswith("mode:"):
            answer = answer.split("\n", 1)[1].strip() if "\n" in answer else ""

        # Retrieve mode has source= lines instead of a dedicated "Sources:" block.
        if not sources:
            seen: set[str] = set()
            for raw in answer.splitlines():
                s = raw.strip()
                if not s.startswith("source="):
                    continue
                src = s.split("=", 1)[1].strip()
                if src and src not in seen:
                    seen.add(src)
                    sources.append(src)

        # Normalize sources: strip AnythingLLM hotdir/storage path artifacts.
        import re
        _hotdir_re = re.compile(r"^file:///app/collector/hotdir/")
        _storage_re = re.compile(r"^file:///app/server/storage/documents/[^/]*/[^/]*/")
        normalized: list[str] = []
        seen_norm: set[str] = set()
        for src in sources:
            s = _hotdir_re.sub("", src)
            s = _storage_re.sub("", s)
            if s and s not in seen_norm:
                seen_norm.add(s)
                normalized.append(s)
        sources = normalized

        # Strip document_metadata tags from answer text.
        answer = re.sub(r"<document_metadata>[^<]*</document_metadata>", "", answer).strip()

        # Truncate answer to max_chars
        if len(answer) > max_chars:
            answer = answer[:max_chars] + "\n...(truncated)"

        # Detect actual mode used from capability output.
        actual_mode = mode
        for raw in lines:
            s = raw.strip()
            if s.startswith("mode:"):
                actual_mode = s.split(":", 1)[1].strip()
                break

        return self._json(
            HTTPStatus.OK,
            {
                "answer": answer,
                "sources": sources,
                "receipt": receipt or None,
                "workspace": workspace,
                "mode": actual_mode,
            },
        )

    def _handle_cap_run(self) -> None:
        """POST /cap/run — execute an allowlisted capability via RPC, return receipted result."""
        clen = int(self.headers.get("Content-Length", "0") or "0")
        if clen <= 0 or clen > 65536:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid content length"})

        try:
            payload = json.loads(self.rfile.read(clen).decode("utf-8"))
        except Exception:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid JSON body"})

        capability = (payload.get("capability") or "").strip()
        if not capability:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "capability is required"})

        cap_args = payload.get("args") or []
        if not isinstance(cap_args, list):
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "args must be a list"})

        # Enforce allowlist
        allowlist = self.config.get("cap_rpc_allowlist") or []
        if capability not in allowlist:
            return self._json(
                HTTPStatus.FORBIDDEN,
                {"error": f"capability '{capability}' not in RPC allowlist", "allowed": allowlist},
            )

        # Enforce RBAC: check if the request token's role allows this capability
        if not self._cap_rpc_role_allows(capability):
            return self._json(
                HTTPStatus.FORBIDDEN,
                {"error": f"capability '{capability}' not permitted for this token role"},
            )

        spine_repo = Path(self.config["spine_repo"])
        ops_bin = spine_repo / "bin" / "ops"
        if not ops_bin.exists():
            return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "ops binary not found"})

        args = [str(ops_bin), "cap", "run", capability] + [str(a) for a in cap_args]

        env = os.environ.copy()
        env["SPINE_REPO"] = str(spine_repo)
        env["SPINE_CODE"] = str(spine_repo)

        timeout = int(self.config.get("cap_rpc_timeout") or 120)
        try:
            p = subprocess.run(
                args,
                capture_output=True,
                timeout=timeout,
                env=env,
                cwd=str(spine_repo),
            )
        except subprocess.TimeoutExpired:
            return self._json(
                HTTPStatus.GATEWAY_TIMEOUT,
                {"error": f"capability '{capability}' timed out ({timeout}s)"},
            )

        stdout = p.stdout.decode("utf-8", errors="replace")
        stderr = p.stderr.decode("utf-8", errors="replace")

        # Parse receipt path and run key from capability runner output
        receipt = ""
        run_key = ""
        for raw in stdout.splitlines():
            s = raw.strip()
            if s.startswith("Receipt:"):
                receipt = s.split("Receipt:", 1)[1].strip()
            elif s.startswith("Run Key:") and not run_key:
                run_key = s.split("Run Key:", 1)[1].strip()

        # Extract capability output between delimiter lines
        lines = stdout.splitlines()
        start_idx = None
        for i, raw in enumerate(lines):
            if raw.strip().lower() == "executing...":
                # Find the delimiter after "Executing..."
                for j in range(i + 1, len(lines)):
                    if _is_output_delim(lines[j]):
                        start_idx = j + 1
                        break
                break

        end_idx = len(lines)
        if start_idx is not None:
            for i in range(start_idx, len(lines)):
                if _is_output_delim(lines[i]):
                    end_idx = i
                    break
            output = "\n".join(lines[start_idx:end_idx]).strip()
        else:
            output = stdout.strip()

        # Truncate output
        max_output = int(self.config.get("max_read_bytes") or 262144)
        if len(output) > max_output:
            output = output[:max_output] + "\n...(truncated)"

        return self._json(
            HTTPStatus.OK if p.returncode == 0 else HTTPStatus.INTERNAL_SERVER_ERROR,
            {
                "capability": capability,
                "status": "done" if p.returncode == 0 else "failed",
                "exit_code": p.returncode,
                "output": output,
                "stderr": stderr[:2000] if p.returncode != 0 else "",
                "receipt": receipt or None,
                "run_key": run_key or None,
            },
        )

    def do_POST(self) -> None:  # noqa: N802
        parsed = urlparse(self.path)
        path = parsed.path.rstrip("/") or "/"

        if path == "/health":
            return self._json(HTTPStatus.METHOD_NOT_ALLOWED, {"error": "use GET"})

        if not self._require_auth():
            return

        if path == "/cap/run":
            return self._handle_cap_run()

        if path == "/rag/ask":
            return self._handle_rag_ask()

        if path != "/inbox/enqueue":
            return self._json(HTTPStatus.NOT_FOUND, {"error": "unknown endpoint"})

        clen = int(self.headers.get("Content-Length", "0") or "0")
        if clen <= 0 or clen > 1024 * 1024:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid content length"})

        try:
            payload = json.loads(self.rfile.read(clen).decode("utf-8"))
        except Exception:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid JSON body"})

        prompt = (payload.get("prompt") or "").strip()
        if not prompt:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "prompt is required"})

        slug = (payload.get("slug") or "task").strip()
        run_id = (payload.get("run_id") or "").strip()
        session_id = (payload.get("session_id") or "").strip()

        spine_repo = Path(self.config["spine_repo"])
        enqueue = spine_repo / "ops/runtime/inbox/agent-enqueue.sh"
        if not enqueue.exists():
            return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "enqueue script missing"})

        args = [str(enqueue), slug]
        if run_id:
            args.append(run_id)

        env = os.environ.copy()
        env["SPINE_REPO"] = str(spine_repo)
        if session_id:
            env["SESSION_ID"] = session_id

        p = subprocess.run(args, input=prompt.encode("utf-8"), capture_output=True, env=env)
        if p.returncode != 0:
            return self._json(
                HTTPStatus.INTERNAL_SERVER_ERROR,
                {"error": "enqueue failed", "stderr": p.stderr.decode("utf-8", errors="replace")},
            )

        out = p.stdout.decode("utf-8", errors="replace")
        enq_path = ""
        for line in out.splitlines():
            if line.startswith("ENQUEUED:"):
                enq_path = line.split("ENQUEUED:", 1)[1].strip()
                break

        return self._json(HTTPStatus.OK, {"status": "enqueued", "path": enq_path or None})

    def log_message(self, fmt: str, *args: Any) -> None:  # noqa: D401
        # Route request logs to stderr (captured by mailroom-bridge.log when started via capability).
        sys.stderr.write("%s - - [%s] %s\n" % (self.address_string(), _now_iso(), fmt % args))


def main() -> None:
    spine_repo = Path(os.environ.get("SPINE_REPO") or os.path.expanduser("~/code/agentic-spine")).resolve()
    binding = spine_repo / "ops/bindings/mailroom.bridge.yaml"
    if not binding.exists():
        _stop(f"missing binding: {binding}")

    # Validate YAML only if yq exists in PATH. (launchd PATH is often minimal)
    if shutil.which("yq"):
        try:
            _sh("yq", "-r", ".", str(binding))
        except Exception:
            _stop(f"invalid YAML: {binding}")

    host = _yq(binding, ".listen.host // \"127.0.0.1\"", "127.0.0.1")
    port = int(_yq(binding, ".listen.port // 8799", "8799"))
    token_env = _yq(binding, ".auth.token_env // \"MAILROOM_BRIDGE_TOKEN\"", "MAILROOM_BRIDGE_TOKEN")
    require_token = _yq(binding, ".auth.require_token // false", "false").lower() == "true"
    max_read = int(_yq(binding, ".limits.max_read_bytes // 262144", "262144"))

    token = os.environ.get(token_env, "") or ""
    if require_token and not token:
        _stop(f"token required by binding, but env var not set: {token_env}")

    # Load cap-RPC allowlist from binding
    cap_rpc_allowlist: list[str] = []
    cap_rpc_timeout = 120
    # RBAC: token → allowed capabilities mapping
    # Key = token value, Value = set of allowed caps (or "*" for full allowlist)
    cap_rpc_roles: dict[str, str | list[str]] = {}
    if shutil.which("yq"):
        try:
            al_raw = _sh("yq", "-r", ".cap_rpc.allowlist[]?", str(binding))
            cap_rpc_allowlist = [s.strip() for s in al_raw.splitlines() if s.strip()]
        except Exception:
            pass
        try:
            t = _yq(binding, ".cap_rpc.timeout // 120", "120")
            cap_rpc_timeout = int(t)
        except (TypeError, ValueError):
            pass
        # Load RBAC roles: each role has token_env + allow (list or "*")
        try:
            role_names_raw = _sh("yq", "-r", ".cap_rpc.roles | keys | .[]?", str(binding))
            for role_name in [r.strip() for r in role_names_raw.splitlines() if r.strip()]:
                role_token_env = _yq(binding, f'.cap_rpc.roles.{role_name}.token_env // ""', "")
                if not role_token_env:
                    continue
                role_token = os.environ.get(role_token_env, "") or ""
                if not role_token:
                    continue
                allow_raw = _yq(binding, f'.cap_rpc.roles.{role_name}.allow', "")
                if allow_raw == "*":
                    cap_rpc_roles[role_token] = "*"
                else:
                    try:
                        allow_list_raw = _sh("yq", "-r", f".cap_rpc.roles.{role_name}.allow[]?", str(binding))
                        allow_list = [c.strip() for c in allow_list_raw.splitlines() if c.strip()]
                        # Constrain to allowlist: roles cannot grant beyond it
                        cap_rpc_roles[role_token] = [c for c in allow_list if c in cap_rpc_allowlist]
                    except Exception:
                        pass
        except Exception:
            pass

    Handler.config = {
        "spine_repo": str(spine_repo),
        "host": host,
        "port": port,
        "token_env": token_env,
        "token": token,
        "max_read_bytes": max_read,
        "cap_rpc_allowlist": cap_rpc_allowlist,
        "cap_rpc_timeout": cap_rpc_timeout,
        "cap_rpc_roles": cap_rpc_roles,
    }

    roles_summary = {env: ("*" if v == "*" else len(v)) for env, v in cap_rpc_roles.items()}
    httpd = ThreadingHTTPServer((host, port), Handler)
    print("mailroom.bridge.serve")
    print(f"spine_repo: {spine_repo}")
    print(f"listen: {host}:{port}")
    print(f"token_required: {bool(token)}")
    print(f"token_env: {token_env}")
    print(f"max_read_bytes: {max_read}")
    print(f"cap_rpc_allowlist: {cap_rpc_allowlist}")
    print(f"cap_rpc_timeout: {cap_rpc_timeout}s")
    print(f"cap_rpc_roles: {len(cap_rpc_roles)} loaded")
    sys.stdout.flush()
    httpd.serve_forever()


if __name__ == "__main__":
    main()
