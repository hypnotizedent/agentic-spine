#!/usr/bin/env python3
"""
mailroom.bridge.serve - minimal HTTP bridge to the spine mailroom.

Contract:
- Reads from canonical runtime root (SPINE_REPO).
- Writes prompts via ops/runtime/inbox/agent-enqueue.sh (mailroom/inbox/queued).
- Token auth enforced by binding (`auth.require_token` + `auth.token_env`).
"""

from __future__ import annotations

import json
import os
import subprocess
import sys
import time
import shutil
from datetime import date, datetime
from http import HTTPStatus
from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
from pathlib import Path
from typing import Any
from urllib.parse import parse_qs, urlparse


def _now_iso() -> str:
    # Use local time string only for diagnostics; do not treat as SSOT.
    return time.strftime("%Y-%m-%dT%H:%M:%S%z")


def _stop(msg: str, code: int = 2) -> None:
    print(f"STOP: {msg}", file=sys.stderr)
    raise SystemExit(code)


def _sh(*args: str) -> str:
    p = subprocess.run(list(args), capture_output=True, text=True)
    if p.returncode != 0:
        raise RuntimeError(p.stderr.strip() or p.stdout.strip() or f"command failed: {' '.join(args)}")
    return p.stdout.strip()


def _yq(binding: Path, expr: str, default: str) -> str:
    try:
        out = _sh("yq", "-r", expr, str(binding))
    except Exception:
        return default
    if out in ("", "null"):
        return default
    return out


def _safe_child(root: Path, rel: str) -> Path:
    # Prevent path traversal.
    rel = rel.lstrip("/")
    p = (root / rel).resolve()
    root_r = root.resolve()
    if p == root_r:
        return p
    if root_r not in p.parents:
        raise ValueError("path escapes root")
    return p


def _read_limited(path: Path, max_bytes: int) -> bytes:
    size = path.stat().st_size
    if size > max_bytes:
        raise ValueError(f"file too large ({size} bytes > max {max_bytes})")
    return path.read_bytes()


def _parse_scope_frontmatter(md: str) -> tuple[dict[str, str], int]:
    """
    Parse a small YAML frontmatter block from a loop scope markdown file.

    We intentionally avoid PyYAML here; loop scope frontmatter is simple
    key: value pairs and that's all we need for the bridge.
    """

    lines = md.splitlines()
    if not lines or lines[0].strip() != "---":
        return {}, 0

    fm: dict[str, str] = {}
    i = 1
    while i < len(lines):
        line = lines[i].rstrip("\n")
        if line.strip() == "---":
            return fm, i + 1
        s = line.strip()
        if not s or s.startswith("#") or ":" not in s:
            i += 1
            continue
        k, v = s.split(":", 1)
        fm[k.strip()] = v.strip().strip('"')
        i += 1
    return {}, 0


def _scope_title(md: str, body_start_line: int) -> str:
    lines = md.splitlines()
    for raw in lines[body_start_line:]:
        s = raw.strip()
        if not s.startswith("#"):
            continue
        # First markdown heading after frontmatter wins.
        title = s.lstrip("#").strip()
        if title.lower().startswith("loop scope:"):
            title = title[len("loop scope:") :].strip()
        return title
    return ""


def _is_open_status(status: str) -> bool:
    return (status or "").strip().lower() in {"active", "draft", "open"}


def _is_output_delim(line: str) -> bool:
    s = (line or "").strip()
    if len(s) < 8:
        return False
    return all(ch in {"─", "-"} for ch in s)


def _reduce_open_loops_from_scopes(scopes_dir: Path) -> list[dict[str, Any]]:
    """
    Reduce open loops from scope files (mailroom/state/loop-scopes/*.scope.md).

    This matches ops/commands/loops.sh semantics:
    - status in {active,draft,open} = open
    - status == closed = closed
    - skip non-loop scope files (e.g. status: authoritative)
    """

    if not scopes_dir.exists() or not scopes_dir.is_dir():
        return []

    loops: list[dict[str, Any]] = []
    for scope_file in sorted(scopes_dir.glob("*.scope.md")):
        try:
            md = scope_file.read_text(encoding="utf-8", errors="replace")
        except OSError:
            continue

        fm, body_start = _parse_scope_frontmatter(md)
        loop_id = (fm.get("loop_id") or "").strip()
        if not loop_id:
            continue

        status = (fm.get("status") or "").strip().lower() or "unknown"
        severity = (fm.get("severity") or "").strip() or "-"
        owner = (fm.get("owner") or "").strip() or "unassigned"

        # Skip non-loop scope files (e.g. status: authoritative).
        if status not in {"active", "draft", "open", "closed"}:
            continue
        if not _is_open_status(status):
            continue

        title = _scope_title(md, body_start) or loop_id
        display_title = title if title != loop_id else ""

        loops.append(
            {
                "loop_id": loop_id,
                "status": status,
                "severity": severity,
                "owner": owner,
                "title": display_title,
            }
        )

    return loops


DAY_TO_INDEX = {
    "MO": 0,
    "TU": 1,
    "WE": 2,
    "TH": 3,
    "FR": 4,
    "SA": 5,
    "SU": 6,
}


def _today_in_timezone(tz_name: str) -> date:
    try:
        from zoneinfo import ZoneInfo

        return datetime.now(ZoneInfo(tz_name)).date()
    except Exception:
        return datetime.now().date()


def _parse_dtstart_local(raw: str) -> datetime | None:
    try:
        return datetime.strptime(raw, "%Y%m%dT%H%M%S")
    except Exception:
        return None


def _parse_byday(raw: Any) -> list[str]:
    if raw is None:
        return []
    if isinstance(raw, list):
        vals = [str(x).strip().upper() for x in raw if str(x).strip()]
    else:
        vals = [x.strip().upper() for x in str(raw).split(",") if x.strip()]
    return [v for v in vals if v in DAY_TO_INDEX]


def _event_occurs_on_date(event: dict[str, Any], on_date: date) -> bool:
    start_raw = str(event.get("dtstart_local", "")).strip()
    start_dt = _parse_dtstart_local(start_raw)
    if start_dt is None:
        return False

    start_date = start_dt.date()
    if on_date < start_date:
        return False

    freq = str(event.get("freq", "DAILY")).strip().upper()
    if freq == "DAILY":
        return True

    if freq == "WEEKLY":
        byday = _parse_byday(event.get("byday"))
        if not byday:
            return on_date.weekday() == start_date.weekday()
        return on_date.weekday() in {DAY_TO_INDEX[d] for d in byday}

    if freq == "MONTHLY":
        return on_date.day == start_date.day

    if freq == "YEARLY":
        return (on_date.month, on_date.day) == (start_date.month, start_date.day)

    return on_date == start_date


def _calendar_today_summary(index_payload: dict[str, Any]) -> dict[str, Any]:
    tz_name = str(index_payload.get("timezone") or "UTC")
    today = _today_in_timezone(tz_name)

    layers = index_payload.get("layers") or []
    if not isinstance(layers, list):
        layers = []
    layer_rank = {name: i for i, name in enumerate(layers)}

    events_raw = index_payload.get("events") or []
    if not isinstance(events_raw, list):
        events_raw = []

    today_events: list[dict[str, Any]] = []
    for item in events_raw:
        if not isinstance(item, dict):
            continue
        if not _event_occurs_on_date(item, today):
            continue

        dtstart_local = str(item.get("dtstart_local", ""))
        parsed = _parse_dtstart_local(dtstart_local)
        hhmm = parsed.strftime("%H:%M") if parsed else "--:--"

        today_events.append(
            {
                "layer": str(item.get("layer", "")),
                "time_local": hhmm,
                "summary": str(item.get("summary", "")),
                "uid": str(item.get("uid", "")),
            }
        )

    today_events.sort(
        key=lambda row: (
            layer_rank.get(row.get("layer", ""), 999),
            row.get("time_local", ""),
            row.get("summary", ""),
        )
    )

    layer_counts: dict[str, int] = {}
    for row in today_events:
        layer = row.get("layer", "")
        layer_counts[layer] = layer_counts.get(layer, 0) + 1

    return {
        "date": today.isoformat(),
        "timezone": tz_name,
        "count": len(today_events),
        "layer_counts": layer_counts,
        "events": today_events,
    }


class Handler(BaseHTTPRequestHandler):
    server_version = "spine-mailroom-bridge/0.1"

    # Set on server startup.
    config: dict[str, Any] = {}

    def _json(self, status: int, obj: Any) -> None:
        body = json.dumps(obj, indent=2, sort_keys=True).encode("utf-8")
        self.send_response(status)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.send_header("Content-Length", str(len(body)))
        self.end_headers()
        self.wfile.write(body)

    def _text(self, status: int, body: str, content_type: str = "text/plain; charset=utf-8") -> None:
        b = body.encode("utf-8")
        self.send_response(status)
        self.send_header("Content-Type", content_type)
        self.send_header("Content-Length", str(len(b)))
        self.end_headers()
        self.wfile.write(b)

    def _extract_request_token(self) -> str:
        """Extract the bearer or X-Spine-Token from the request."""
        hdr = self.headers.get("Authorization", "")
        if hdr.startswith("Bearer "):
            return hdr.removeprefix("Bearer ").strip()
        return (self.headers.get("X-Spine-Token", "") or "").strip()

    def _cf_access_ok(self) -> bool:
        """Check Cloudflare Access JWT auth (service-token flow).

        CF Access validates at the edge and injects a signed JWT in the
        configured header.  The bridge trusts the tunnel (no signature
        check) and validates only the audience claim to prevent cross-app
        reuse.
        """
        if not self.config.get("cf_access_enabled"):
            return False

        jwt_header = self.config.get("cf_access_jwt_header") or "Cf-Access-Jwt-Assertion"
        jwt_raw = (self.headers.get(jwt_header) or "").strip()
        if not jwt_raw:
            return False

        # Decode JWT payload (second segment, base64url-encoded).
        parts = jwt_raw.split(".")
        if len(parts) != 3:
            return False

        import base64
        try:
            payload_b64 = parts[1]
            # base64url: pad to multiple of 4
            padding = 4 - len(payload_b64) % 4
            if padding != 4:
                payload_b64 += "=" * padding
            payload = json.loads(base64.urlsafe_b64decode(payload_b64))
        except Exception:
            return False

        # Validate audience claim if configured.
        cf_access_aud = self.config.get("cf_access_aud") or ""
        if cf_access_aud:
            token_aud = payload.get("aud") or []
            if isinstance(token_aud, str):
                token_aud = [token_aud]
            if cf_access_aud not in token_aud:
                return False

        return True

    def _auth_ok(self) -> bool:
        # CF Access auth (service-token via Cloudflare edge)
        if self._cf_access_ok():
            return True

        primary_token = self.config.get("token") or ""
        if not primary_token:
            # Tailnet-only deployments can run without a token (explicitly documented).
            return True

        req_token = self._extract_request_token()
        if not req_token:
            return False

        # Accept primary token
        if req_token == primary_token:
            return True

        # Accept any RBAC role token
        roles = self.config.get("cap_rpc_roles") or {}
        return req_token in roles

    def _require_auth(self) -> bool:
        if self._auth_ok():
            return True
        self._json(HTTPStatus.UNAUTHORIZED, {"error": "unauthorized"})
        return False

    def _cap_rpc_role_allows(self, capability: str) -> bool:
        """Check if the request token's RBAC role allows the given capability."""
        # CF Access auth gets operator-level (full allowlist) access.
        if self._cf_access_ok():
            return True

        roles = self.config.get("cap_rpc_roles") or {}
        if not roles:
            # No roles configured: any authenticated token gets full allowlist.
            return True

        req_token = self._extract_request_token()
        if req_token not in roles:
            # Token is the primary auth token but not in roles — full access.
            primary_token = self.config.get("token") or ""
            if req_token == primary_token:
                return True
            return False

        allow = roles[req_token]
        if allow == "*":
            return True
        return capability in allow

    def _capability_approval(self, capability: str) -> str:
        """Return approval mode for a capability from ops/capabilities.yaml."""
        caps_file = Path(self.config["spine_repo"]) / "ops/capabilities.yaml"
        if not shutil.which("yq") or not caps_file.exists():
            return ""
        try:
            out = _sh("yq", "-r", f'.capabilities."{capability}".approval // ""', str(caps_file))
        except Exception:
            return ""
        return (out or "").strip()

    def do_GET(self) -> None:  # noqa: N802
        parsed = urlparse(self.path)
        path = parsed.path.rstrip("/") or "/"
        qs = parse_qs(parsed.query or "")

        if path == "/health":
            token_required = bool(self.config.get("token"))
            return self._json(
                HTTPStatus.OK,
                {
                    "status": "ok",
                    "now": _now_iso(),
                    "listen": {"host": self.config.get("host"), "port": self.config.get("port")},
                    "auth": {"token_required": token_required, "token_env": self.config.get("token_env")},
                },
            )

        if not self._require_auth():
            return

        spine_repo = Path(self.config["spine_repo"])
        outbox_root = spine_repo / "mailroom/outbox"
        receipts_root = spine_repo / "receipts/sessions"
        scopes_dir = spine_repo / "mailroom/state/loop-scopes"
        max_read = int(self.config.get("max_read_bytes") or 262144)

        if path == "/loops/open":
            loops = _reduce_open_loops_from_scopes(scopes_dir)
            # Stable ordering for clients.
            severity_rank = {"critical": 0, "high": 1, "medium": 2, "low": 3}
            loops.sort(
                key=lambda r: (
                    severity_rank.get((r.get("severity") or "medium").lower(), 9),
                    r.get("owner", ""),
                    r.get("loop_id", ""),
                )
            )
            return self._json(HTTPStatus.OK, {"open_loops": loops, "count": len(loops)})

        if path == "/outbox/list":
            rel = (qs.get("path") or [""])[0]
            try:
                base = _safe_child(outbox_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not base.exists():
                return self._json(HTTPStatus.NOT_FOUND, {"error": "not found"})
            if not base.is_dir():
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "path is not a directory"})
            items = []
            for child in sorted(base.iterdir()):
                try:
                    st = child.stat()
                except FileNotFoundError:
                    continue
                items.append(
                    {
                        "path": str(child.relative_to(outbox_root)),
                        "type": "dir" if child.is_dir() else "file",
                        "size": st.st_size,
                        "mtime": int(st.st_mtime),
                    }
                )
            return self._json(HTTPStatus.OK, {"root": str(base.relative_to(outbox_root)), "items": items})

        if path == "/outbox/read":
            rel = (qs.get("path") or [""])[0]
            try:
                p = _safe_child(outbox_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not p.exists() or not p.is_file():
                return self._json(HTTPStatus.NOT_FOUND, {"error": "not found"})
            try:
                data = _read_limited(p, max_read)
            except ValueError as e:
                return self._json(HTTPStatus.REQUEST_ENTITY_TOO_LARGE, {"error": str(e)})
            # Best-effort text, fallback to bytes via latin-1.
            try:
                text = data.decode("utf-8")
                return self._text(HTTPStatus.OK, text, content_type="text/plain; charset=utf-8")
            except UnicodeDecodeError:
                return self._text(HTTPStatus.OK, data.decode("latin-1"), content_type="application/octet-stream")

        if path == "/calendar/feed":
            layer = ((qs.get("layer") or ["all"])[0] or "all").strip().lower()
            if layer in ("", "all"):
                rel = "calendar/calendar-global.ics"
            else:
                allowed_layers = {"infrastructure", "automation", "identity", "personal", "spine", "life"}
                if layer not in allowed_layers:
                    return self._json(
                        HTTPStatus.BAD_REQUEST,
                        {"error": "invalid layer", "allowed": ["all", *sorted(allowed_layers)]},
                    )
                rel = f"calendar/calendar-{layer}.ics"

            try:
                p = _safe_child(outbox_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not p.exists() or not p.is_file():
                return self._json(
                    HTTPStatus.NOT_FOUND,
                    {"error": "calendar feed not found", "hint": "run calendar.generate first", "layer": layer},
                )
            try:
                data = _read_limited(p, max_read)
            except ValueError as e:
                return self._json(HTTPStatus.REQUEST_ENTITY_TOO_LARGE, {"error": str(e)})
            return self._text(HTTPStatus.OK, data.decode("utf-8", errors="replace"), content_type="text/calendar; charset=utf-8")

        if path == "/calendar/today":
            try:
                index_path = _safe_child(outbox_root, "calendar/calendar-index.json")
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid calendar index path"})

            if not index_path.exists() or not index_path.is_file():
                return self._json(
                    HTTPStatus.NOT_FOUND,
                    {"error": "calendar index not found", "hint": "run calendar.generate first"},
                )
            try:
                data = _read_limited(index_path, max_read)
            except ValueError as e:
                return self._json(HTTPStatus.REQUEST_ENTITY_TOO_LARGE, {"error": str(e)})

            try:
                index_payload = json.loads(data.decode("utf-8", errors="replace"))
            except json.JSONDecodeError:
                return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "invalid calendar index JSON"})

            if not isinstance(index_payload, dict):
                return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "calendar index must be an object"})

            summary = _calendar_today_summary(index_payload)
            summary["source"] = str(index_path.relative_to(outbox_root))
            return self._json(HTTPStatus.OK, summary)

        if path == "/receipts/read":
            rel = (qs.get("path") or [""])[0]
            # Allow e.g. "RCAP-.../receipt.md" or "RCAP-.../output.txt"
            try:
                p = _safe_child(receipts_root, rel)
            except ValueError:
                return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid path"})
            if not p.exists() or not p.is_file():
                return self._json(HTTPStatus.NOT_FOUND, {"error": "not found"})
            try:
                data = _read_limited(p, max_read)
            except ValueError as e:
                return self._json(HTTPStatus.REQUEST_ENTITY_TOO_LARGE, {"error": str(e)})
            return self._text(HTTPStatus.OK, data.decode("utf-8", errors="replace"))

        return self._json(HTTPStatus.NOT_FOUND, {"error": "unknown endpoint"})

    def _handle_rag_ask(self) -> None:
        """POST /rag/ask — governed RAG query via rag.anythingllm.ask capability."""
        clen = int(self.headers.get("Content-Length", "0") or "0")
        if clen <= 0 or clen > 65536:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid content length"})

        try:
            payload = json.loads(self.rfile.read(clen).decode("utf-8"))
        except Exception:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid JSON body"})

        question = (payload.get("question") or "").strip()
        if not question:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "question is required"})

        workspace = (payload.get("workspace") or "agentic-spine").strip()
        mode = (payload.get("mode") or "auto").strip()
        if mode not in ("auto", "chat", "retrieve"):
            return self._json(HTTPStatus.BAD_REQUEST, {"error": f"invalid mode: {mode} (expected: auto, chat, retrieve)"})
        try:
            max_chars = int(payload.get("context_max_chars") or 10000)
        except (TypeError, ValueError):
            max_chars = 10000
        if max_chars < 100:
            max_chars = 100
        if max_chars > 100000:
            max_chars = 100000

        spine_repo = Path(self.config["spine_repo"])
        ops_bin = spine_repo / "bin" / "ops"
        if not ops_bin.exists():
            return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "ops binary not found"})

        # Call: ./bin/ops cap run rag.anythingllm.ask "<question>" --mode <mode> --workspace <ws>
        args = [
            str(ops_bin), "cap", "run", "rag.anythingllm.ask",
            question, "--mode", mode, "--workspace", workspace,
        ]

        env = os.environ.copy()
        env["SPINE_REPO"] = str(spine_repo)
        env["SPINE_CODE"] = str(spine_repo)

        try:
            p = subprocess.run(
                args,
                capture_output=True,
                timeout=120,
                env=env,
                cwd=str(spine_repo),
            )
        except subprocess.TimeoutExpired:
            return self._json(HTTPStatus.GATEWAY_TIMEOUT, {"error": "RAG query timed out (120s)"})

        stdout = p.stdout.decode("utf-8", errors="replace")
        stderr = p.stderr.decode("utf-8", errors="replace")

        if p.returncode != 0:
            return self._json(
                HTTPStatus.INTERNAL_SERVER_ERROR,
                {"error": "rag query failed", "stderr": stderr[:2000], "stdout": stdout[:2000]},
            )

        # Parse capability-runner output:
        # - receipt path is emitted in stdout as "Receipt: ..."
        # - useful payload must come from the final capability execution block
        #   after "== PRECONDITIONS OK ==" to avoid precondition output contamination.
        lines = stdout.splitlines()
        receipt = ""
        for raw in lines:
            s = raw.strip()
            if s.startswith("Receipt:"):
                receipt = s.split("Receipt:", 1)[1].strip()
                continue

        pre_ok_idx = -1
        for i, raw in enumerate(lines):
            if raw.strip() == "== PRECONDITIONS OK ==":
                pre_ok_idx = i

        executing_idx = -1
        for i, raw in enumerate(lines):
            if pre_ok_idx >= 0 and i <= pre_ok_idx:
                continue
            if raw.strip().lower() == "executing...":
                executing_idx = i

        start_idx = None
        for i, raw in enumerate(lines):
            if executing_idx >= 0 and i <= executing_idx:
                continue
            if _is_output_delim(raw):
                start_idx = i + 1
                break
        if start_idx is None:
            start_idx = executing_idx + 1 if executing_idx >= 0 else 0

        end_idx = len(lines)
        for i in range(start_idx, len(lines)):
            if _is_output_delim(lines[i]):
                end_idx = i
                break

        payload_lines = lines[start_idx:end_idx]
        answer_lines: list[str] = []
        sources: list[str] = []
        in_sources = False

        for line in payload_lines:
            if line.strip() == "Sources:":
                in_sources = True
                continue
            if in_sources:
                s = line.strip()
                if s.startswith("- "):
                    sources.append(s[2:])
                elif s:
                    sources.append(s)
            else:
                answer_lines.append(line)

        answer = "\n".join(answer_lines).strip()
        if not answer:
            answer = stdout.strip()

        # Prefer the capability payload starting at mode: (chat/retrieve) when preface noise exists.
        if not answer.startswith("mode:"):
            mode_pos = answer.find("mode:")
            if mode_pos >= 0:
                answer = answer[mode_pos:].strip()

        if answer.startswith("mode:"):
            answer = answer.split("\n", 1)[1].strip() if "\n" in answer else ""

        # Retrieve mode has source= lines instead of a dedicated "Sources:" block.
        if not sources:
            seen: set[str] = set()
            for raw in answer.splitlines():
                s = raw.strip()
                if not s.startswith("source="):
                    continue
                src = s.split("=", 1)[1].strip()
                if src and src not in seen:
                    seen.add(src)
                    sources.append(src)

        # Normalize sources: strip AnythingLLM hotdir/storage path artifacts.
        import re
        _hotdir_re = re.compile(r"^file:///app/collector/hotdir/")
        _storage_re = re.compile(r"^file:///app/server/storage/documents/[^/]*/[^/]*/")
        normalized: list[str] = []
        seen_norm: set[str] = set()
        for src in sources:
            s = _hotdir_re.sub("", src)
            s = _storage_re.sub("", s)
            if s and s not in seen_norm:
                seen_norm.add(s)
                normalized.append(s)
        sources = normalized

        # Strip document_metadata tags from answer text.
        answer = re.sub(r"<document_metadata>[^<]*</document_metadata>", "", answer).strip()

        # Truncate answer to max_chars
        if len(answer) > max_chars:
            answer = answer[:max_chars] + "\n...(truncated)"

        # Detect actual mode used from capability output.
        actual_mode = mode
        for raw in lines:
            s = raw.strip()
            if s.startswith("mode:"):
                actual_mode = s.split(":", 1)[1].strip()
                break

        return self._json(
            HTTPStatus.OK,
            {
                "answer": answer,
                "sources": sources,
                "receipt": receipt or None,
                "workspace": workspace,
                "mode": actual_mode,
            },
        )

    def _handle_cap_run(self) -> None:
        """POST /cap/run — execute an allowlisted capability via RPC, return receipted result."""
        clen = int(self.headers.get("Content-Length", "0") or "0")
        if clen <= 0 or clen > 65536:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid content length"})

        try:
            payload = json.loads(self.rfile.read(clen).decode("utf-8"))
        except Exception:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid JSON body"})

        capability = (payload.get("capability") or "").strip()
        if not capability:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "capability is required"})

        cap_args = payload.get("args") or []
        if not isinstance(cap_args, list):
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "args must be a list"})
        confirm_raw = payload.get("confirm", False)
        if not isinstance(confirm_raw, bool):
            return self._json(
                HTTPStatus.BAD_REQUEST,
                {
                    "error": "confirm must be a boolean",
                    "error_code": "invalid_confirm_type",
                },
            )
        confirm = confirm_raw

        # Enforce allowlist
        allowlist = self.config.get("cap_rpc_allowlist") or []
        if capability not in allowlist:
            return self._json(
                HTTPStatus.FORBIDDEN,
                {"error": f"capability '{capability}' not in RPC allowlist", "allowed": allowlist},
            )

        # Enforce RBAC: check if the request token's role allows this capability
        if not self._cap_rpc_role_allows(capability):
            return self._json(
                HTTPStatus.FORBIDDEN,
                {"error": f"capability '{capability}' not permitted for this token role"},
            )

        spine_repo = Path(self.config["spine_repo"])
        ops_bin = spine_repo / "bin" / "ops"
        if not ops_bin.exists():
            return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "ops binary not found"})

        args = [str(ops_bin), "cap", "run", capability] + [str(a) for a in cap_args]
        approval = self._capability_approval(capability)
        if approval == "manual" and not confirm:
            return self._json(
                HTTPStatus.BAD_REQUEST,
                {
                    "error": f"capability '{capability}' requires confirm=true for manual approval",
                    "error_code": "manual_confirmation_required",
                    "capability": capability,
                    "approval": "manual",
                    "hint": "rerun with confirm=true",
                },
            )

        env = os.environ.copy()
        env["SPINE_REPO"] = str(spine_repo)
        env["SPINE_CODE"] = str(spine_repo)
        stdin_text = b"yes\n" if approval == "manual" and confirm else None

        timeout = int(self.config.get("cap_rpc_timeout") or 120)
        try:
            p = subprocess.run(
                args,
                input=stdin_text,
                capture_output=True,
                timeout=timeout,
                env=env,
                cwd=str(spine_repo),
            )
        except subprocess.TimeoutExpired:
            return self._json(
                HTTPStatus.GATEWAY_TIMEOUT,
                {"error": f"capability '{capability}' timed out ({timeout}s)"},
            )

        stdout = p.stdout.decode("utf-8", errors="replace")
        stderr = p.stderr.decode("utf-8", errors="replace")

        # Parse receipt path and run key from capability runner output
        receipt = ""
        run_key = ""
        for raw in stdout.splitlines():
            s = raw.strip()
            if s.startswith("Receipt:"):
                receipt = s.split("Receipt:", 1)[1].strip()
            elif s.startswith("Run Key:") and not run_key:
                run_key = s.split("Run Key:", 1)[1].strip()

        # Extract capability output between delimiter lines
        lines = stdout.splitlines()
        start_idx = None
        for i, raw in enumerate(lines):
            if raw.strip().lower() == "executing...":
                # Find the delimiter after "Executing..."
                for j in range(i + 1, len(lines)):
                    if _is_output_delim(lines[j]):
                        start_idx = j + 1
                        break
                break

        end_idx = len(lines)
        if start_idx is not None:
            for i in range(start_idx, len(lines)):
                if _is_output_delim(lines[i]):
                    end_idx = i
                    break
            output = "\n".join(lines[start_idx:end_idx]).strip()
        else:
            output = stdout.strip()

        # Truncate output
        max_output = int(self.config.get("max_read_bytes") or 262144)
        if len(output) > max_output:
            output = output[:max_output] + "\n...(truncated)"

        return self._json(
            HTTPStatus.OK if p.returncode == 0 else HTTPStatus.INTERNAL_SERVER_ERROR,
            {
                "capability": capability,
                "status": "done" if p.returncode == 0 else "failed",
                "exit_code": p.returncode,
                "output": output,
                "stderr": stderr[:2000] if p.returncode != 0 else "",
                "approval": approval or "auto",
                "confirm": confirm,
                "receipt": receipt or None,
                "run_key": run_key or None,
            },
        )

    def do_POST(self) -> None:  # noqa: N802
        parsed = urlparse(self.path)
        path = parsed.path.rstrip("/") or "/"

        if path == "/health":
            return self._json(HTTPStatus.METHOD_NOT_ALLOWED, {"error": "use GET"})

        if not self._require_auth():
            return

        if path == "/cap/run":
            return self._handle_cap_run()

        if path == "/rag/ask":
            return self._handle_rag_ask()

        if path != "/inbox/enqueue":
            return self._json(HTTPStatus.NOT_FOUND, {"error": "unknown endpoint"})

        clen = int(self.headers.get("Content-Length", "0") or "0")
        if clen <= 0 or clen > 1024 * 1024:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid content length"})

        try:
            payload = json.loads(self.rfile.read(clen).decode("utf-8"))
        except Exception:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "invalid JSON body"})

        prompt = (payload.get("prompt") or "").strip()
        if not prompt:
            return self._json(HTTPStatus.BAD_REQUEST, {"error": "prompt is required"})

        slug = (payload.get("slug") or "task").strip()
        run_id = (payload.get("run_id") or "").strip()
        session_id = (payload.get("session_id") or "").strip()

        spine_repo = Path(self.config["spine_repo"])
        enqueue = spine_repo / "ops/runtime/inbox/agent-enqueue.sh"
        if not enqueue.exists():
            return self._json(HTTPStatus.INTERNAL_SERVER_ERROR, {"error": "enqueue script missing"})

        args = [str(enqueue), slug]
        if run_id:
            args.append(run_id)

        env = os.environ.copy()
        env["SPINE_REPO"] = str(spine_repo)
        if session_id:
            env["SESSION_ID"] = session_id

        p = subprocess.run(args, input=prompt.encode("utf-8"), capture_output=True, env=env)
        if p.returncode != 0:
            return self._json(
                HTTPStatus.INTERNAL_SERVER_ERROR,
                {"error": "enqueue failed", "stderr": p.stderr.decode("utf-8", errors="replace")},
            )

        out = p.stdout.decode("utf-8", errors="replace")
        enq_path = ""
        for line in out.splitlines():
            if line.startswith("ENQUEUED:"):
                enq_path = line.split("ENQUEUED:", 1)[1].strip()
                break

        return self._json(HTTPStatus.OK, {"status": "enqueued", "path": enq_path or None})

    def log_message(self, fmt: str, *args: Any) -> None:  # noqa: D401
        # Route request logs to stderr (captured by mailroom-bridge.log when started via capability).
        sys.stderr.write("%s - - [%s] %s\n" % (self.address_string(), _now_iso(), fmt % args))


def main() -> None:
    spine_repo = Path(os.environ.get("SPINE_REPO") or os.path.expanduser("~/code/agentic-spine")).resolve()
    binding = spine_repo / "ops/bindings/mailroom.bridge.yaml"
    if not binding.exists():
        _stop(f"missing binding: {binding}")

    # Validate YAML only if yq exists in PATH. (launchd PATH is often minimal)
    if shutil.which("yq"):
        try:
            _sh("yq", "-r", ".", str(binding))
        except Exception:
            _stop(f"invalid YAML: {binding}")

    host = _yq(binding, ".listen.host // \"127.0.0.1\"", "127.0.0.1")
    port = int(_yq(binding, ".listen.port // 8799", "8799"))
    token_env = _yq(binding, ".auth.token_env // \"MAILROOM_BRIDGE_TOKEN\"", "MAILROOM_BRIDGE_TOKEN")
    require_token = _yq(binding, ".auth.require_token // false", "false").lower() == "true"
    max_read = int(_yq(binding, ".limits.max_read_bytes // 262144", "262144"))

    # Cloudflare Access service-token auth config
    cf_access_enabled = _yq(binding, ".auth.cf_access.enabled // false", "false").lower() == "true"
    cf_access_aud = _yq(binding, '.auth.cf_access.aud // ""', "")
    cf_access_jwt_header = _yq(binding, '.auth.cf_access.jwt_header // "Cf-Access-Jwt-Assertion"', "Cf-Access-Jwt-Assertion")

    token = os.environ.get(token_env, "") or ""
    if require_token and not token:
        _stop(f"token required by binding, but env var not set: {token_env}")

    # Load cap-RPC allowlist from binding
    cap_rpc_allowlist: list[str] = []
    cap_rpc_timeout = 120
    # RBAC: token → allowed capabilities mapping
    # Key = token value, Value = set of allowed caps (or "*" for full allowlist)
    cap_rpc_roles: dict[str, str | list[str]] = {}
    if shutil.which("yq"):
        try:
            al_raw = _sh("yq", "-r", ".cap_rpc.allowlist[]?", str(binding))
            cap_rpc_allowlist = [s.strip() for s in al_raw.splitlines() if s.strip()]
        except Exception:
            pass
        try:
            t = _yq(binding, ".cap_rpc.timeout // 120", "120")
            cap_rpc_timeout = int(t)
        except (TypeError, ValueError):
            pass
        # Load RBAC roles: each role has token_env + allow (list or "*")
        try:
            role_names_raw = _sh("yq", "-r", ".cap_rpc.roles | keys | .[]?", str(binding))
            for role_name in [r.strip() for r in role_names_raw.splitlines() if r.strip()]:
                role_token_env = _yq(binding, f'.cap_rpc.roles.{role_name}.token_env // ""', "")
                if not role_token_env:
                    continue
                role_token = os.environ.get(role_token_env, "") or ""
                if not role_token:
                    continue
                allow_raw = _yq(binding, f'.cap_rpc.roles.{role_name}.allow', "")
                if allow_raw == "*":
                    cap_rpc_roles[role_token] = "*"
                else:
                    try:
                        allow_list_raw = _sh("yq", "-r", f".cap_rpc.roles.{role_name}.allow[]?", str(binding))
                        allow_list = [c.strip() for c in allow_list_raw.splitlines() if c.strip()]
                        # Constrain to allowlist: roles cannot grant beyond it
                        cap_rpc_roles[role_token] = [c for c in allow_list if c in cap_rpc_allowlist]
                    except Exception:
                        pass
        except Exception:
            pass

    Handler.config = {
        "spine_repo": str(spine_repo),
        "host": host,
        "port": port,
        "token_env": token_env,
        "token": token,
        "max_read_bytes": max_read,
        "cap_rpc_allowlist": cap_rpc_allowlist,
        "cap_rpc_timeout": cap_rpc_timeout,
        "cap_rpc_roles": cap_rpc_roles,
        "cf_access_enabled": cf_access_enabled,
        "cf_access_aud": cf_access_aud,
        "cf_access_jwt_header": cf_access_jwt_header,
    }

    roles_summary = {env: ("*" if v == "*" else len(v)) for env, v in cap_rpc_roles.items()}
    httpd = ThreadingHTTPServer((host, port), Handler)
    print("mailroom.bridge.serve")
    print(f"spine_repo: {spine_repo}")
    print(f"listen: {host}:{port}")
    print(f"token_required: {bool(token)}")
    print(f"token_env: {token_env}")
    print(f"max_read_bytes: {max_read}")
    print(f"cap_rpc_allowlist: {cap_rpc_allowlist}")
    print(f"cap_rpc_timeout: {cap_rpc_timeout}s")
    print(f"cap_rpc_roles: {len(cap_rpc_roles)} loaded")
    print(f"cf_access_enabled: {cf_access_enabled}")
    sys.stdout.flush()
    httpd.serve_forever()


if __name__ == "__main__":
    main()
