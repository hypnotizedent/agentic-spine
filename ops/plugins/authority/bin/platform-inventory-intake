#!/usr/bin/env bash
set -euo pipefail

ROOT="${SPINE_ROOT:-$HOME/code/agentic-spine}"

if [[ "${1:-}" == "--" ]]; then
  shift
fi

python3 - "$ROOT" "$@" <<'PY'
from __future__ import annotations

import argparse
from datetime import datetime, timezone
from pathlib import Path
import re
import sys

import yaml


def fail(message: str) -> None:
    print(f"platform.inventory.intake FAIL: {message}", file=sys.stderr)
    raise SystemExit(1)


def load_yaml(path: Path) -> dict:
    try:
        with path.open("r", encoding="utf-8") as handle:
            data = yaml.safe_load(handle) or {}
    except Exception as exc:
        fail(f"unable to parse YAML {path}: {exc}")
    if not isinstance(data, dict):
        fail(f"expected mapping at YAML root: {path}")
    return data


def save_yaml(path: Path, data: dict) -> None:
    path.write_text(yaml.safe_dump(data, sort_keys=False), encoding="utf-8")


def now_utc() -> datetime:
    return datetime.now(timezone.utc)


def now_iso() -> str:
    return now_utc().strftime("%Y-%m-%dT%H:%M:%SZ")


def today_iso() -> str:
    return now_utc().strftime("%Y-%m-%d")


def normalize_number(value: float):
    if abs(value - round(value)) < 1e-9:
        return int(round(value))
    return round(value, 6)


def require_file(path: Path, label: str) -> None:
    if not path.is_file():
        fail(f"missing {label}: {path}")


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(prog="platform-inventory-intake")
    sub = parser.add_subparsers(dest="command", required=True)

    scaffold = sub.add_parser("scaffold")
    scaffold.add_argument("--class", dest="item_class", choices=["part", "material"], required=True)
    scaffold.add_argument("--id", dest="item_id", required=True)
    scaffold.add_argument("--owner-agent", required=True)
    scaffold.add_argument("--site", required=True)
    scaffold.add_argument("--location-id", required=True)
    scaffold.add_argument("--runbook-path", required=True)
    scaffold.add_argument("--dry-run", action="store_true")

    validate = sub.add_parser("validate")
    validate.add_argument("--file", dest="file_path", required=True)

    receive = sub.add_parser("receive")
    receive.add_argument("--class", dest="item_class", choices=["part", "material"], required=True)
    receive.add_argument("--id", dest="item_id", required=True)
    receive.add_argument("--qty", type=float, required=True)
    receive.add_argument("--uom", required=True)
    receive.add_argument("--to-location-id", required=True)
    receive.add_argument("--owner-agent", required=True)
    receive.add_argument("--evidence-ref", action="append", default=[])
    receive.add_argument("--loop-id", default="LOOP-INVENTORY-UNSPECIFIED")
    receive.add_argument("--proposal-id", default="CP-TBD")

    issue = sub.add_parser("issue")
    issue.add_argument("--class", dest="item_class", choices=["part", "material"], required=True)
    issue.add_argument("--id", dest="item_id", required=True)
    issue.add_argument("--qty", type=float, required=True)
    issue.add_argument("--uom", required=True)
    issue.add_argument("--from-location-id", required=True)
    issue.add_argument("--owner-agent", required=True)
    issue.add_argument("--evidence-ref", action="append", default=[])
    issue.add_argument("--loop-id", default="LOOP-INVENTORY-UNSPECIFIED")
    issue.add_argument("--proposal-id", default="CP-TBD")

    move = sub.add_parser("move")
    move.add_argument("--class", dest="item_class", choices=["part", "material"], required=True)
    move.add_argument("--id", dest="item_id", required=True)
    move.add_argument("--qty", type=float, required=True)
    move.add_argument("--uom", required=True)
    move.add_argument("--from-location-id", required=True)
    move.add_argument("--to-location-id", required=True)
    move.add_argument("--owner-agent", required=True)
    move.add_argument("--evidence-ref", action="append", default=[])
    move.add_argument("--loop-id", default="LOOP-INVENTORY-UNSPECIFIED")
    move.add_argument("--proposal-id", default="CP-TBD")

    count = sub.add_parser("count")
    count.add_argument("--class", dest="item_class", choices=["part", "material"], required=True)
    count.add_argument("--id", dest="item_id", required=True)
    count.add_argument("--counted-qty", type=float, required=True)
    count.add_argument("--uom", required=True)
    count.add_argument("--location-id", required=True)
    count.add_argument("--owner-agent", required=True)
    count.add_argument("--reason", default="")
    count.add_argument("--evidence-ref", action="append", default=[])
    count.add_argument("--loop-id", default="LOOP-INVENTORY-UNSPECIFIED")
    count.add_argument("--proposal-id", default="CP-TBD")

    reconcile = sub.add_parser("reconcile")
    reconcile.add_argument("--domain", choices=["network", "ha", "media"], required=True)
    reconcile.add_argument("--emit-intake-stubs", dest="emit_intake_stubs", action="store_true")
    reconcile.add_argument("--no-emit-intake-stubs", dest="emit_intake_stubs", action="store_false")
    reconcile.set_defaults(emit_intake_stubs=True)
    reconcile.add_argument("--write-stubs", action="store_true")
    reconcile.add_argument("--limit", type=int, default=250)
    reconcile.add_argument("--offset", type=int, default=0)
    reconcile.add_argument("--owner-agent", dest="owner_agent", default="")
    reconcile.add_argument("--location-id", dest="location_id", default="")
    reconcile.add_argument(
        "--runbook-path",
        dest="runbook_path",
        default="docs/governance/generated/W43_INVENTORY_INTAKE_UNION_LOCK_20260223.md",
    )

    return parser


def resolve_inventory_doc(root: Path, item_class: str) -> tuple[Path, str]:
    if item_class == "part":
        return root / "ops/bindings/hardware.parts.inventory.yaml", "parts"
    return root / "ops/bindings/business.inventory.catalog.yaml", "materials"


def load_inventory_item(root: Path, item_class: str, item_id: str) -> tuple[Path, dict, str, list[dict], dict, int]:
    doc_path, key = resolve_inventory_doc(root, item_class)
    require_file(doc_path, f"{item_class} inventory binding")
    doc = load_yaml(doc_path)
    rows = doc.get(key)
    if not isinstance(rows, list):
        fail(f"{doc_path}: {key} must be a list")

    for idx, row in enumerate(rows):
        if isinstance(row, dict) and str(row.get("id", "")).strip() == item_id:
            return doc_path, doc, key, rows, row, idx

    fail(f"item not found for class={item_class}: {item_id}")


def load_agents(root: Path) -> set[str]:
    agents_path = root / "ops/bindings/agents.registry.yaml"
    require_file(agents_path, "agents binding")
    agents_doc = load_yaml(agents_path)
    return {
        str(row.get("id", "")).strip()
        for row in (agents_doc.get("agents") or [])
        if isinstance(row, dict) and str(row.get("id", "")).strip()
    }


def load_locations(root: Path) -> dict[str, str]:
    locations_path = root / "ops/bindings/inventory.locations.yaml"
    require_file(locations_path, "inventory locations binding")
    locations_doc = load_yaml(locations_path)
    out: dict[str, str] = {}
    for row in (locations_doc.get("locations") or []):
        if not isinstance(row, dict):
            continue
        loc_id = str(row.get("id", "")).strip()
        site = str(row.get("site", "")).strip()
        if loc_id:
            out[loc_id] = site
    return out


def load_ledger(root: Path) -> tuple[Path, dict, list[dict]]:
    ledger_path = root / "ops/bindings/inventory.transaction.ledger.yaml"
    require_file(ledger_path, "inventory transaction ledger")
    ledger_doc = load_yaml(ledger_path)
    txns = ledger_doc.get("transactions")
    if not isinstance(txns, list):
        fail(f"{ledger_path}: transactions must be a list")
    return ledger_path, ledger_doc, txns


def parse_float(value, label: str) -> float:
    try:
        return float(value)
    except Exception:
        fail(f"{label} must be numeric")


def assert_owner(owner_agent: str, agents: set[str]) -> None:
    if owner_agent not in agents:
        fail(f"owner_agent not found in agents.registry.yaml: {owner_agent}")


def assert_location(location_id: str, site: str, locations: dict[str, str], label: str) -> None:
    if location_id not in locations:
        fail(f"{label} location not found in inventory.locations.yaml: {location_id}")
    if site and locations[location_id] != site:
        fail(f"{label} location site mismatch ({location_id} site={locations[location_id]} expected={site})")


def assert_uom(item: dict, uom: str) -> None:
    expected = str(item.get("unit_of_measure", "")).strip()
    if expected and expected != uom:
        fail(f"uom mismatch: expected {expected}, got {uom}")


def make_txn_id(existing: set[str], item_class: str, item_id: str, action: str) -> str:
    base = f"ITXN-{now_utc().strftime('%Y%m%d-%H%M%S')}-{item_class}-{item_id}-{action}"
    candidate = base
    counter = 1
    while candidate in existing:
        candidate = f"{base}-{counter}"
        counter += 1
    return candidate


def append_ledger_row(
    txns: list[dict],
    item_class: str,
    item_id: str,
    action: str,
    qty_delta: float,
    uom: str,
    from_location_id: str,
    to_location_id: str,
    evidence_refs: list[str],
    owner_agent: str,
    loop_id: str,
    proposal_id: str,
) -> dict:
    existing = {
        str(row.get("txn_id", "")).strip()
        for row in txns
        if isinstance(row, dict) and str(row.get("txn_id", "")).strip()
    }
    row = {
        "txn_id": make_txn_id(existing, item_class, item_id, action),
        "item_class": item_class,
        "item_id": item_id,
        "action": action,
        "qty_delta": normalize_number(qty_delta),
        "uom": uom,
        "from_location_id": from_location_id,
        "to_location_id": to_location_id,
        "evidence_refs": [x for x in evidence_refs if x],
        "owner_agent": owner_agent,
        "recorded_at": now_iso(),
        "loop_id": loop_id,
        "proposal_id": proposal_id,
        "status": "recorded",
    }
    txns.append(row)
    return row


def run_scaffold(args, root: Path, agents: set[str], locations: dict[str, str]) -> None:
    item_id = args.item_id.strip()
    if not re.fullmatch(r"^[a-z0-9][a-z0-9-]*$", item_id):
        fail("--id must match ^[a-z0-9][a-z0-9-]*$")

    assert_owner(args.owner_agent, agents)
    assert_location(args.location_id, args.site, locations, "scaffold")

    runbook_path = args.runbook_path
    runbook_target = Path(runbook_path) if runbook_path.startswith("/") else (root / runbook_path)
    if not runbook_target.is_file() and not args.dry_run:
        fail(f"runbook_path does not exist: {runbook_path}")

    now = now_utc()
    date_stamp = now.strftime("%Y%m%d")
    ts = now.strftime("%Y-%m-%dT%H:%M:%SZ")
    intake_id = f"ITK-{date_stamp}-{args.item_class}-{item_id}"
    payload = {
        "intake_id": intake_id,
        "class": args.item_class,
        "item_id": item_id,
        "status": "draft",
        "lifecycle_status": "draft",
        "owner_agent": args.owner_agent,
        "site": args.site,
        "location_id": args.location_id,
        "evidence_refs": [],
        "runbook_path": runbook_path,
        "touches_runtime": False,
        "runtime_homes": {},
        "required_homes": {
            "owner_agent": args.owner_agent,
            "site": args.site,
            "location_id": args.location_id,
            "evidence_refs": [],
            "runbook_path": runbook_path,
            "infisical_namespace": "",
            "vaultwarden_item": "",
            "gitea_repo": "",
            "observability_probe": "",
        },
        "created_at": ts,
        "updated_at": ts,
    }

    text = yaml.safe_dump(payload, sort_keys=False)
    if args.dry_run:
        print(text, end="")
        return

    intake_dir = root / "mailroom/outbox/intake"
    intake_dir.mkdir(parents=True, exist_ok=True)
    output_path = intake_dir / f"{intake_id}.yaml"
    if output_path.exists():
        fail(f"intake file already exists: {output_path}")
    output_path.write_text(text, encoding="utf-8")
    print(f"platform.inventory.intake OK: wrote {output_path}")


def run_validate(args, root: Path, agents: set[str], locations: dict[str, str]) -> None:
    target = Path(args.file_path)
    if not target.is_absolute():
        target = (root / target).resolve()
    if not target.is_file():
        fail(f"intake file not found: {target}")

    doc = load_yaml(target)
    errors: list[str] = []

    required = [
        "intake_id",
        "class",
        "item_id",
        "status",
        "lifecycle_status",
        "owner_agent",
        "site",
        "location_id",
        "evidence_refs",
        "runbook_path",
        "touches_runtime",
        "runtime_homes",
        "required_homes",
        "created_at",
        "updated_at",
    ]
    for key in required:
        if key not in doc:
            errors.append(f"missing key: {key}")

    if str(doc.get("class", "")).strip() not in {"part", "material"}:
        errors.append("class must be part|material")

    lifecycle_values = {"draft", "proposed", "approved", "recorded", "active", "depleted", "retired", "rma"}
    for key in ("status", "lifecycle_status"):
        if str(doc.get(key, "")).strip() not in lifecycle_values:
            errors.append(f"{key} must be one of {sorted(lifecycle_values)}")

    intake_id = str(doc.get("intake_id", "")).strip()
    if not re.fullmatch(r"^ITK-\d{8}-(part|material)-[a-z0-9][a-z0-9-]*$", intake_id):
        errors.append("intake_id format invalid")

    owner_agent = str(doc.get("owner_agent", "")).strip()
    if owner_agent not in agents:
        errors.append(f"owner_agent not found in agents.registry.yaml: {owner_agent}")

    location_id = str(doc.get("location_id", "")).strip()
    site = str(doc.get("site", "")).strip()
    if location_id not in locations:
        errors.append(f"location_id not found in inventory.locations.yaml: {location_id}")
    elif locations[location_id] != site:
        errors.append(f"site/location mismatch ({site} vs {locations[location_id]})")

    runbook_path = str(doc.get("runbook_path", "")).strip()
    if runbook_path:
        runbook_target = Path(runbook_path) if runbook_path.startswith("/") else (root / runbook_path)
        if not runbook_target.is_file():
            errors.append(f"runbook_path does not exist: {runbook_path}")

    if not isinstance(doc.get("evidence_refs"), list):
        errors.append("evidence_refs must be a list")

    runtime_homes = doc.get("runtime_homes")
    if not isinstance(runtime_homes, dict):
        errors.append("runtime_homes must be a mapping")
        runtime_homes = {}

    if bool(doc.get("touches_runtime", False)):
        for key in ("infisical_namespace", "vaultwarden_item", "gitea_repo", "observability_probe"):
            if not str(runtime_homes.get(key, "")).strip():
                errors.append(f"touches_runtime=true requires runtime_homes.{key}")

    if errors:
        for err in errors:
            print(f"platform.inventory.intake FAIL: {target} :: {err}", file=sys.stderr)
        raise SystemExit(1)

    print(f"platform.inventory.intake PASS: {target}")


def run_transaction(args, root: Path, agents: set[str], locations: dict[str, str], mode: str) -> None:
    assert_owner(args.owner_agent, agents)

    doc_path, doc, key, rows, item, idx = load_inventory_item(root, args.item_class, args.item_id)
    current_qty = parse_float(item.get("on_hand_qty", 0), "on_hand_qty")
    assert_uom(item, args.uom)

    ledger_path, ledger_doc, txns = load_ledger(root)

    if mode == "receive":
        if args.qty <= 0:
            fail("receive requires --qty > 0")
        assert_location(args.to_location_id, str(item.get("site", "")).strip(), locations, "receive")
        qty_delta = args.qty
        new_qty = current_qty + args.qty
        from_loc = ""
        to_loc = args.to_location_id
        action = "receive"
    elif mode == "issue":
        if args.qty <= 0:
            fail("issue requires --qty > 0")
        if str(item.get("location_id", "")).strip() != args.from_location_id:
            fail(f"issue from-location mismatch: item location is {item.get('location_id')}")
        assert_location(args.from_location_id, str(item.get("site", "")).strip(), locations, "issue")
        qty_delta = -args.qty
        new_qty = current_qty + qty_delta
        if new_qty < 0:
            fail("negative inventory rejected for issue action")
        from_loc = args.from_location_id
        to_loc = ""
        action = "issue"
    elif mode == "move":
        if args.qty <= 0:
            fail("move requires --qty > 0")
        if args.qty > current_qty:
            fail("move qty exceeds on_hand_qty")
        if str(item.get("location_id", "")).strip() != args.from_location_id:
            fail(f"move from-location mismatch: item location is {item.get('location_id')}")
        assert_location(args.from_location_id, str(item.get("site", "")).strip(), locations, "move-from")
        assert_location(args.to_location_id, "", locations, "move-to")
        qty_delta = 0.0
        new_qty = current_qty
        from_loc = args.from_location_id
        to_loc = args.to_location_id
        action = "move"
        item["location_id"] = args.to_location_id
        item["site"] = locations[args.to_location_id]
    elif mode == "count":
        counted_qty = args.counted_qty
        if counted_qty < 0:
            fail("counted quantity cannot be negative")
        if str(item.get("location_id", "")).strip() != args.location_id:
            fail(f"count location mismatch: item location is {item.get('location_id')}")
        assert_location(args.location_id, str(item.get("site", "")).strip(), locations, "count")
        qty_delta = counted_qty - current_qty
        if qty_delta < 0 and not str(args.reason or "").strip():
            fail("negative adjustment requires --reason")
        new_qty = counted_qty
        from_loc = args.location_id
        to_loc = args.location_id
        action = "adjust"
        item["last_counted_at"] = today_iso()
    else:
        fail(f"unsupported transaction mode: {mode}")

    item["on_hand_qty"] = normalize_number(new_qty)
    if mode in {"receive", "issue"}:
        item["location_id"] = to_loc or from_loc or str(item.get("location_id", "")).strip()
    if mode in {"receive", "move", "count"}:
        final_loc = str(item.get("location_id", "")).strip()
        if final_loc in locations:
            item["site"] = locations[final_loc]

    doc["updated_at"] = today_iso()
    rows[idx] = item
    doc[key] = rows

    evidence_refs = list(args.evidence_ref or [])
    if mode == "count" and str(args.reason or "").strip():
        evidence_refs.append(f"reason:{args.reason.strip()}")

    row = append_ledger_row(
        txns=txns,
        item_class=args.item_class,
        item_id=args.item_id,
        action=action,
        qty_delta=qty_delta,
        uom=args.uom,
        from_location_id=from_loc,
        to_location_id=to_loc,
        evidence_refs=evidence_refs,
        owner_agent=args.owner_agent,
        loop_id=args.loop_id,
        proposal_id=args.proposal_id,
    )
    ledger_doc["updated_at"] = today_iso()

    save_yaml(doc_path, doc)
    save_yaml(ledger_path, ledger_doc)

    print(f"platform.inventory.intake OK: {mode} recorded {row['txn_id']}")


def load_domain_ledger(root: Path, domain: str) -> tuple[Path, dict]:
    ledger_map = {
        "network": root / "ops/bindings/network.devices.ledger.yaml",
        "ha_devices": root / "ops/bindings/ha.devices.ledger.yaml",
        "ha_automations": root / "ops/bindings/ha.automations.ledger.yaml",
        "media": root / "ops/bindings/media.content.ledger.yaml",
    }
    path = ledger_map[domain]
    require_file(path, f"{domain} ledger binding")
    return path, load_yaml(path)


def observed_items_for_domain(root: Path, domain: str) -> list[dict]:
    items: list[dict] = []

    if domain == "network":
        home_observed = load_yaml(root / "ops/bindings/network.unifi.home.clients.observed.yaml")
        shop_observed = load_yaml(root / "ops/bindings/network.unifi.shop.clients.observed.yaml")

        def add_network_rows(doc: dict, source_name: str):
            source_stamp = str(doc.get("generated_at") or now_iso())
            for row in doc.get("devices") or []:
                if not isinstance(row, dict):
                    continue
                item_id = str(row.get("id", "")).strip()
                if not item_id:
                    continue
                observed_status = str(row.get("status", "active")).strip().lower()
                if observed_status not in {"active", "online", "present"}:
                    continue
                site = str(row.get("site", "")).strip() or "unknown"
                items.append(
                    {
                        "id": item_id,
                        "class": "device",
                        "source_system": source_name,
                        "first_seen_at": source_stamp,
                        "location_or_site": site,
                    }
                )

        add_network_rows(home_observed, "network.unifi.home.clients.observed")
        add_network_rows(shop_observed, "network.unifi.shop.clients.observed")
        return items

    if domain == "ha":
        devices = load_yaml(root / "ops/bindings/ha.device.map.yaml")
        automations = load_yaml(root / "ops/bindings/ha.automations.yaml")
        device_ts = str(devices.get("generated") or "2026-02-23T00:00:00Z")
        auto_ts = str(automations.get("generated") or "2026-02-23T00:00:00Z")

        for row in devices.get("devices") or []:
            if not isinstance(row, dict):
                continue
            item_id = str(row.get("ha_device_id", "")).strip()
            if not item_id:
                continue
            area = str(row.get("area") or "").strip() or "home"
            items.append(
                {
                    "id": item_id,
                    "class": "device",
                    "source_system": "ha.device.map",
                    "first_seen_at": device_ts,
                    "location_or_site": area,
                }
            )

        for row in automations.get("automations") or []:
            if not isinstance(row, dict):
                continue
            item_id = str(row.get("entity_id", "")).strip()
            if not item_id:
                continue
            items.append(
                {
                    "id": item_id,
                    "class": "automation",
                    "source_system": "ha.automations",
                    "first_seen_at": auto_ts,
                    "location_or_site": "home",
                }
            )
        return items

    if domain == "media":
        snapshot = load_yaml(root / "ops/bindings/media.content.snapshot.yaml")
        source_stamp = str(snapshot.get("generated_at") or now_iso())

        def add_media_rows(values, item_class: str):
            if not isinstance(values, list):
                return
            for row in values:
                if isinstance(row, str):
                    item_id = row.strip()
                elif isinstance(row, dict):
                    item_id = str(row.get("id", "")).strip()
                else:
                    continue
                if not item_id:
                    continue
                items.append(
                    {
                        "id": item_id,
                        "class": item_class,
                        "source_system": "media.content.snapshot",
                        "first_seen_at": source_stamp,
                        "location_or_site": "shop",
                    }
                )

        add_media_rows(snapshot.get("movies"), "movie")
        add_media_rows(snapshot.get("tv"), "tv")
        add_media_rows(snapshot.get("music"), "music")
        return items

    fail(f"unsupported reconcile domain: {domain}")
    return items


def reconcile_default_owner_agent(domain: str) -> str:
    if domain == "media":
        return "media-agent"
    return "home-assistant-agent"


def reconcile_default_location_id(domain: str) -> str:
    if domain == "media":
        return "shop-supplies-bin-b1"
    return "TODO-location-id"


def reconcile_intake_class(source_class: str) -> str:
    if source_class in {"movie", "tv", "music"}:
        return "material"
    return "part"


def reconcile_normalized_item_id(item_id: str) -> str:
    return re.sub(r"[^a-z0-9-]+", "-", item_id.lower()).strip("-") or "item"


def build_reconcile_stub_payload(
    *,
    row: dict,
    owner_agent: str,
    location_id: str,
    runbook_path: str,
    location_site: str,
) -> tuple[str, str, dict, dict]:
    item_id = str(row["id"])
    item_class = str(row["class"])
    intake_class = reconcile_intake_class(item_class)
    normalized_id = reconcile_normalized_item_id(item_id)
    intake_id = f"ITK-{today_iso().replace('-', '')}-{intake_class}-{normalized_id}"
    ts = now_iso()
    stub_payload = {
        "intake_id": intake_id,
        "class": intake_class,
        "item_id": item_id,
        "status": "draft",
        "lifecycle_status": "draft",
        "owner_agent": owner_agent,
        "site": location_site,
        "location_id": location_id,
        "evidence_refs": [],
        "runbook_path": runbook_path,
        "touches_runtime": False,
        "runtime_homes": {},
        "required_homes": {
            "owner_agent": owner_agent,
            "site": location_site,
            "location_id": location_id,
            "evidence_refs": [],
            "runbook_path": runbook_path,
            "infisical_namespace": "",
            "vaultwarden_item": "",
            "gitea_repo": "",
            "observability_probe": "",
        },
        "created_at": ts,
        "updated_at": ts,
    }
    suggested_intake = {
        "class": intake_class,
        "id": item_id,
        "owner-agent": owner_agent,
        "site": location_site,
        "location-id": location_id,
        "runbook-path": runbook_path,
    }
    return intake_id, f"mailroom/outbox/intake/{intake_id}.yaml", suggested_intake, stub_payload


def run_reconcile(args, root: Path, agents: set[str], locations: dict[str, str]) -> None:
    domain = args.domain
    if args.limit < 0:
        fail("--limit must be >= 0")
    if args.limit > 10000:
        fail("--limit must be <= 10000")
    if args.offset < 0:
        fail("--offset must be >= 0")

    owner_agent = str(args.owner_agent or "").strip() or reconcile_default_owner_agent(domain)
    location_id = str(args.location_id or "").strip() or reconcile_default_location_id(domain)
    runbook_path = str(args.runbook_path or "").strip() or "docs/governance/generated/W43_INVENTORY_INTAKE_UNION_LOCK_20260223.md"
    location_site = locations.get(location_id, "")

    if args.write_stubs:
        assert_owner(owner_agent, agents)
        if location_id not in locations:
            fail(f"write-stubs requires valid location_id in inventory.locations.yaml: {location_id}")
        location_site = locations[location_id]
        runbook_target = Path(runbook_path) if runbook_path.startswith("/") else (root / runbook_path)
        if not runbook_target.is_file():
            fail(f"write-stubs requires existing runbook_path: {runbook_path}")

    if domain == "ha":
        devices_path, devices_ledger = load_domain_ledger(root, "ha_devices")
        autos_path, autos_ledger = load_domain_ledger(root, "ha_automations")
        ledger_paths = [devices_path, autos_path]
        rows: list[dict] = []
        rows.extend([x for x in (devices_ledger.get("items") or []) if isinstance(x, dict)])
        rows.extend([x for x in (autos_ledger.get("items") or []) if isinstance(x, dict)])
    else:
        path, ledger = load_domain_ledger(root, domain)
        ledger_paths = [path]
        rows = [x for x in (ledger.get("items") or []) if isinstance(x, dict)]

    managed_status = {"approved", "ignored"}
    managed: dict[tuple[str, str], dict] = {}
    for row in rows:
        item_id = str(row.get("id", "")).strip()
        item_class = str(row.get("class", "")).strip()
        status = str(row.get("status", "")).strip().lower()
        if item_id and item_class and status in managed_status:
            managed[(item_id, item_class)] = row

    observed_items = observed_items_for_domain(root, domain)
    unmanaged_candidates: list[dict] = []
    for row in observed_items:
        key = (row["id"], row["class"])
        if key in managed:
            continue
        suggested_site = location_site or str(row.get("location_or_site", "")).strip() or "unknown"
        intake_id, intake_file, suggested_intake, stub_payload = build_reconcile_stub_payload(
            row=row,
            owner_agent=owner_agent,
            location_id=location_id,
            runbook_path=runbook_path,
            location_site=suggested_site,
        )
        entry = {
            "id": row["id"],
            "class": row["class"],
            "source_system": row["source_system"],
            "first_seen_at": row["first_seen_at"],
            "location_or_site": row["location_or_site"],
        }
        if args.emit_intake_stubs:
            entry["suggested_intake_file"] = intake_file
            entry["suggested_intake"] = suggested_intake
        unmanaged_candidates.append(
            {
                "entry": entry,
                "intake_id": intake_id,
                "stub_payload": stub_payload,
            }
        )

    unmanaged_candidates.sort(
        key=lambda item: (
            str(item["entry"].get("class", "")).lower(),
            str(item["entry"].get("id", "")).lower(),
        )
    )
    unmanaged_total = len(unmanaged_candidates)
    selected_candidates = unmanaged_candidates[args.offset : args.offset + args.limit] if args.limit else []
    selected_unmanaged = [item["entry"] for item in selected_candidates]

    stubs_written = 0
    stubs_skipped_existing = 0
    stubs_failed = 0
    if args.write_stubs:
        intake_dir = root / "mailroom/outbox/intake"
        intake_dir.mkdir(parents=True, exist_ok=True)
        for candidate in selected_candidates:
            output_path = intake_dir / f"{candidate['intake_id']}.yaml"
            if output_path.exists():
                stubs_skipped_existing += 1
                continue
            try:
                output_path.write_text(
                    yaml.safe_dump(candidate["stub_payload"], sort_keys=False),
                    encoding="utf-8",
                )
                stubs_written += 1
            except Exception as exc:
                stubs_failed += 1
                print(
                    f"platform.inventory.intake FAIL: write-stubs error for {output_path}: {exc}",
                    file=sys.stderr,
                )

    payload = {
        "domain": domain,
        "ledger_paths": [str(path.relative_to(root)) for path in ledger_paths],
        "observed_count": len(observed_items),
        "managed_count": len(observed_items) - unmanaged_total,
        "unmanaged_count": unmanaged_total,
        "unmanaged_items": selected_unmanaged,
    }
    print(yaml.safe_dump(payload, sort_keys=False), end="")
    print(f"unmanaged_total: {unmanaged_total}", file=sys.stderr)
    print(f"selected_for_stub: {len(selected_candidates)}", file=sys.stderr)
    print(f"stubs_written: {stubs_written}", file=sys.stderr)
    print(f"stubs_skipped_existing: {stubs_skipped_existing}", file=sys.stderr)
    print(f"stubs_failed: {stubs_failed}", file=sys.stderr)

    if args.write_stubs and stubs_failed > 0:
        fail(f"write-stubs failed for {stubs_failed} intake file(s)")


def main() -> None:
    if len(sys.argv) < 2:
        fail("missing root argument")

    root = Path(sys.argv[1]).expanduser().resolve()
    parser = build_parser()
    args = parser.parse_args(sys.argv[2:])

    agents = load_agents(root)
    locations = load_locations(root)

    if args.command == "scaffold":
        run_scaffold(args, root, agents, locations)
        return
    if args.command == "validate":
        run_validate(args, root, agents, locations)
        return
    if args.command == "receive":
        run_transaction(args, root, agents, locations, "receive")
        return
    if args.command == "issue":
        run_transaction(args, root, agents, locations, "issue")
        return
    if args.command == "move":
        run_transaction(args, root, agents, locations, "move")
        return
    if args.command == "count":
        run_transaction(args, root, agents, locations, "count")
        return
    if args.command == "reconcile":
        run_reconcile(args, root, agents, locations)
        return

    fail(f"unsupported command: {args.command}")


if __name__ == "__main__":
    main()
PY
