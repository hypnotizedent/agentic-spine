#!/usr/bin/env bash
set -euo pipefail

ROOT="${SPINE_ROOT:-$(cd "$(dirname "${BASH_SOURCE[0]}")/../../../.." && pwd)}"
VERIFY_TOPOLOGY="$ROOT/ops/plugins/verify/bin/verify-topology"
VERIFY_PACK="$ROOT/ops/plugins/verify/bin/verify-pack"
REGISTRY="$ROOT/ops/bindings/gate.registry.yaml"
TOPOLOGY="$ROOT/ops/bindings/gate.execution.topology.yaml"
DOMAIN_PROFILES="$ROOT/ops/bindings/gate.domain.profiles.yaml"
PROFILE_CONTRACT="$ROOT/ops/bindings/verify.run.profile.contract.yaml"
CLASS_CONTRACT="$ROOT/ops/bindings/verify.failure.classification.contract.yaml"
HISTORY_DIR="$ROOT/ops/plugins/verify/state"
HISTORY_FILE="$HISTORY_DIR/verify-failure-class-history.ndjson"
PASS_STREAK_FILE="$HISTORY_DIR/gate-pass-streak.json"
MAPFILE_COMPAT="$ROOT/ops/plugins/verify/bin/bash-mapfile-compat.sh"

# shellcheck disable=SC1090
source "$MAPFILE_COMPAT"
if [[ "${BASH_ENV:-}" != "$MAPFILE_COMPAT" ]]; then
  if [[ -n "${BASH_ENV:-}" ]]; then
    export SPINE_MAPFILE_COMPAT_CHAIN="${BASH_ENV}"
  fi
  export BASH_ENV="$MAPFILE_COMPAT"
fi

fail() {
  echo "verify.run FAIL: $*" >&2
  exit 1
}

[[ -x "$VERIFY_TOPOLOGY" ]] || fail "missing verify runtime: $VERIFY_TOPOLOGY"
[[ -x "$VERIFY_PACK" ]] || fail "missing verify pack runtime: $VERIFY_PACK"
[[ -f "$REGISTRY" ]] || fail "missing gate registry: $REGISTRY"
[[ -f "$TOPOLOGY" ]] || fail "missing topology binding: $TOPOLOGY"
[[ -f "$DOMAIN_PROFILES" ]] || fail "missing domain profiles binding: $DOMAIN_PROFILES"
[[ -f "$PROFILE_CONTRACT" ]] || fail "missing verify profile contract: $PROFILE_CONTRACT"
[[ -f "$CLASS_CONTRACT" ]] || fail "missing failure classification contract: $CLASS_CONTRACT"
command -v yq >/dev/null 2>&1 || fail "missing dependency: yq"
command -v jq >/dev/null 2>&1 || fail "missing dependency: jq"

usage() {
  cat <<'USAGE'
verify.run

Usage:
  verify-run fast [--json] [--shadow]
  verify-run domain <domain_id> [--json] [--shadow]
  verify-run release [--json] [--shadow]

Scopes:
  fast    => class-driven invariants only (contract profile)
  domain  => class-driven invariants + freshness (contract profile)
  release => full release suite

Flags:
  --shadow   run wrapper and legacy path in parallel and emit parity diff
  --json     emit machine-readable JSON output
USAGE
}

json_mode=0
shadow_mode=0

if [[ "${1:-}" == "--" ]]; then
  shift
fi

scope="${1:-}"
shift || true

case "$scope" in
  fast|domain|release) ;;
  -h|--help|"") usage; exit 0 ;;
  *) fail "unknown scope '$scope' (expected fast|domain|release)" ;;
esac

target_domain=""
if [[ "$scope" == "domain" ]]; then
  [[ $# -ge 1 ]] || fail "domain scope requires <domain_id>"
  target_domain="$1"
  shift
fi

while [[ $# -gt 0 ]]; do
  case "$1" in
    --json) json_mode=1; shift ;;
    --shadow) shadow_mode=1; shift ;;
    *) fail "unknown argument: $1" ;;
  esac
done

declare -a freshness_keywords=()
mapfile -t freshness_keywords < <(yq e -r '.freshness_keywords[]' "$CLASS_CONTRACT")

gate_class_for_id() {
  local gid="$1"
  yq e -r ".gates[] | select(.id == \"$gid\") | .gate_class // \"\"" "$REGISTRY" 2>/dev/null | head -n1
}

gate_retired_for_id() {
  local gid="$1"
  yq e -r ".gates[] | select(.id == \"$gid\") | (.retired // false | tostring)" "$REGISTRY" 2>/dev/null | head -n1
}

normalize_domain() {
  local raw="${1:-}"
  case "$raw" in
    core) echo "core" ;;
    loop-gap|loop_gap) echo "loop_gap" ;;
    home-automation) echo "home" ;;
    finance-ops) echo "finance" ;;
    automation) echo "n8n" ;;
    photos) echo "immich" ;;
    identity|email|calendar|microsoft) echo "microsoft" ;;
    *) echo "$raw" ;;
  esac
}

class_in_set() {
  local needle="$1"
  shift || true
  local item
  for item in "$@"; do
    [[ "$item" == "$needle" ]] && return 0
  done
  return 1
}

unique_ids() {
  awk 'NF && !seen[$0]++'
}

array_to_json() {
  if [[ "$#" -eq 0 ]]; then
    printf '[]\n'
    return 0
  fi
  printf '%s\n' "$@" | jq -R -s 'split("\n") | map(select(length > 0))'
}

collect_domain_candidate_ids() {
  local raw_domain="$1"
  local domain
  local tmp_ids gid
  domain="$(normalize_domain "$raw_domain")"

  tmp_ids="$(mktemp)"

  while IFS= read -r gid; do
    [[ -n "$gid" ]] || continue
    printf '%s\n' "$gid" >> "$tmp_ids"
  done < <(yq e -r ".gate_assignments[] | select((.primary_domain == \"$domain\") or ((.secondary_domains // []) | index(\"$domain\"))) | .gate_id" "$TOPOLOGY" 2>/dev/null || true)

  if [[ ! -s "$tmp_ids" ]]; then
    while IFS= read -r gid; do
      [[ -n "$gid" ]] || continue
      printf '%s\n' "$gid" >> "$tmp_ids"
    done < <(yq e -r ".domains.\"$raw_domain\".gate_ids[]?" "$DOMAIN_PROFILES" 2>/dev/null || true)

    if [[ "$domain" != "$raw_domain" ]]; then
      while IFS= read -r gid; do
        [[ -n "$gid" ]] || continue
        printf '%s\n' "$gid" >> "$tmp_ids"
      done < <(yq e -r ".domains.\"$domain\".gate_ids[]?" "$DOMAIN_PROFILES" 2>/dev/null || true)
    fi
  fi

  awk 'NF && !seen[$0]++' "$tmp_ids" | sort -V
  rm -f "$tmp_ids"
}

collect_ids_for_domain_and_classes() {
  local domain="$1"
  shift || true
  local -a classes=("$@")
  local gid gate_class retired

  while IFS= read -r gid; do
    [[ -n "$gid" ]] || continue
    gate_class="$(gate_class_for_id "$gid")"
    retired="$(gate_retired_for_id "$gid")"
    [[ "$retired" == "true" ]] && continue
    class_in_set "$gate_class" "${classes[@]-}" || continue
    echo "$gid"
  done < <(collect_domain_candidate_ids "$domain")
}

collect_core_ids_by_classes() {
  local -a classes=("$@")
  local gid gate_class retired

  while IFS= read -r gid; do
    [[ -n "$gid" ]] || continue
    gate_class="$(gate_class_for_id "$gid")"
    retired="$(gate_retired_for_id "$gid")"
    [[ "$retired" == "true" ]] && continue
    class_in_set "$gate_class" "${classes[@]-}" || continue
    echo "$gid"
  done < <(yq e -r '.core_mode.core_gate_ids[]?' "$TOPOLOGY")
}

run_json_cmd() {
  local -a cmd=("$@")
  local out rc
  set +e
  out="$("${cmd[@]}" --json 2>/dev/null)"
  rc=$?
  set -e

  if [[ -z "$out" ]] || ! jq -e . >/dev/null 2>&1 <<<"$out"; then
    out='{"total":0,"pass":0,"fail":1,"skipped_inline":0,"skipped_retired":0,"receipt_integrity_warnings":0,"failing_ids":[]}'
    rc=1
  else
    out="$(jq -c . <<<"$out")"
  fi

  printf '%s\t%s\n' "$rc" "$out"
}

merge_json_results() {
  local a="$1"
  local b="$2"
  jq -cn --argjson a "$a" --argjson b "$b" '
    {
      total: (($a.total // 0) + ($b.total // 0)),
      pass: (($a.pass // 0) + ($b.pass // 0)),
      fail: (($a.fail // 0) + ($b.fail // 0)),
      skipped_inline: (($a.skipped_inline // 0) + ($b.skipped_inline // 0)),
      skipped_retired: (($a.skipped_retired // 0) + ($b.skipped_retired // 0)),
      receipt_integrity_warnings: (($a.receipt_integrity_warnings // 0) + ($b.receipt_integrity_warnings // 0)),
      failing_ids: ((($a.failing_ids // []) + ($b.failing_ids // [])) | unique)
    }
  '
}

classify_failing_ids() {
  local failing_json="$1"
  local -a deterministic=()
  local -a freshness=()
  local -a gate_bug=()
  local -a ids=()

  mapfile -t ids < <(jq -r '.[]?' <<<"$failing_json")
  local gid script_rel name desc blob kw

  for gid in "${ids[@]-}"; do
    [[ -n "$gid" ]] || continue

    script_rel="$(yq e -r ".gates[] | select(.id == \"$gid\") | .check_script // \"\"" "$REGISTRY" 2>/dev/null || true)"
    if [[ -z "$script_rel" || "$script_rel" == "null" || ! -x "$ROOT/$script_rel" ]]; then
      gate_bug+=("$gid")
      continue
    fi

    name="$(yq e -r ".gates[] | select(.id == \"$gid\") | .name // \"\"" "$REGISTRY" 2>/dev/null || true)"
    desc="$(yq e -r ".gates[] | select(.id == \"$gid\") | .description // \"\"" "$REGISTRY" 2>/dev/null || true)"
    blob="${name} ${desc}"

    is_freshness=0
    for kw in "${freshness_keywords[@]-}"; do
      [[ -n "$kw" ]] || continue
      if printf '%s\n' "$blob" | grep -Fqi -- "$kw"; then
        is_freshness=1
        break
      fi
    done

    if [[ "$is_freshness" -eq 1 ]]; then
      freshness+=("$gid")
    else
      deterministic+=("$gid")
    fi
  done

  jq -n \
    --argjson deterministic "$(array_to_json "${deterministic[@]-}")" \
    --argjson freshness "$(array_to_json "${freshness[@]-}")" \
    --argjson gate_bug "$(array_to_json "${gate_bug[@]-}")" \
    '{deterministic:$deterministic, freshness:$freshness, gate_bug:$gate_bug}'
}

append_history() {
  local scope_label="$1"
  local run_result_json="$2"
  local class_json="$3"

  mkdir -p "$HISTORY_DIR"

  jq -cn \
    --arg ts "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
    --arg scope "$scope_label" \
    --arg run_key "${SPINE_CAP_RUN_KEY:-manual}" \
    --argjson result "$run_result_json" \
    --argjson failure_class "$class_json" \
    '{timestamp_utc:$ts,scope:$scope,run_key:$run_key,result:$result,failure_class:$failure_class}' >> "$HISTORY_FILE"
}

update_gate_pass_streak() {
  local scope_label="$1"
  local domain_label="$2"
  local run_result_json="$3"
  local tmp_file now_utc prev_json scope_ids_json failing_ids_json
  local include_core
  local -a scope_gate_ids=()
  local -a classes=()
  local -a split=()
  local gid

  mkdir -p "$HISTORY_DIR"
  now_utc="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

  if [[ -f "$PASS_STREAK_FILE" ]] && jq -e . >/dev/null 2>&1 <"$PASS_STREAK_FILE"; then
    prev_json="$(cat "$PASS_STREAK_FILE")"
  else
    prev_json='{}'
  fi

  case "$scope_label" in
    fast)
      while IFS=$'\t' read -r fast_domain class_csv; do
        [[ -n "$fast_domain" ]] || continue
        IFS=',' read -r -a split <<< "$class_csv"
        classes=()
        for gid in "${split[@]-}"; do
          [[ -n "$gid" ]] && classes+=("$gid")
        done
        if [[ "$(normalize_domain "$fast_domain")" == "core" ]]; then
          while IFS= read -r gid; do
            [[ -n "$gid" ]] && scope_gate_ids+=("$gid")
          done < <(collect_core_ids_by_classes "${classes[@]-}")
        else
          while IFS= read -r gid; do
            [[ -n "$gid" ]] && scope_gate_ids+=("$gid")
          done < <(collect_ids_for_domain_and_classes "$fast_domain" "${classes[@]-}")
        fi
      done < <(yq e -r '.profiles.fast.domains[] | [.domain, (.classes | join(","))] | @tsv' "$PROFILE_CONTRACT")
      ;;
    domain)
      include_core="$(yq e -r '.profiles.domain.include_core_base // true' "$PROFILE_CONTRACT")"
      if [[ "$include_core" == "true" ]]; then
        mapfile -t classes < <(yq e -r '.profiles.domain.core_base.classes[]' "$PROFILE_CONTRACT")
        while IFS= read -r gid; do
          [[ -n "$gid" ]] && scope_gate_ids+=("$gid")
        done < <(collect_core_ids_by_classes "${classes[@]-}")
      fi

      mapfile -t classes < <(yq e -r '.profiles.domain.target.classes[]' "$PROFILE_CONTRACT")
      while IFS= read -r gid; do
        [[ -n "$gid" ]] && scope_gate_ids+=("$gid")
      done < <(collect_ids_for_domain_and_classes "$domain_label" "${classes[@]-}")
      ;;
    release)
      mapfile -t scope_gate_ids < <(yq e -r '.gates[] | select((.retired // false) != true) | .id' "$REGISTRY")
      ;;
    *)
      scope_gate_ids=()
      ;;
  esac

  mapfile -t scope_gate_ids < <(printf '%s\n' "${scope_gate_ids[@]-}" | unique_ids)
  scope_ids_json="$(printf '%s\n' "${scope_gate_ids[@]-}" | jq -R -s 'split("\n") | map(select(length > 0))')"

  failing_ids_json="$(jq -c '.failing_ids // []' <<<"$run_result_json")"

  tmp_file="$(mktemp)"
  jq -cn \
    --arg now "$now_utc" \
    --argjson prev "$prev_json" \
    --argjson scope_ids "$scope_ids_json" \
    --argjson failing "$failing_ids_json" \
    '
      reduce $scope_ids[] as $gid ($prev;
        .[$gid] = (
          ($prev[$gid] // {streak: 0, last_pass: null, last_fail: null}) as $p |
          if ($failing | index($gid)) != null then
            ($p + {streak: 0, last_fail: $now})
          else
            ($p + {streak: (($p.streak // 0) + 1), last_pass: $now})
          end
        )
      )
    ' > "$tmp_file"

  mv "$tmp_file" "$PASS_STREAK_FILE"
}

run_wrapper() {
  local scope_label="$1"
  local domain_label="$2"
  local wrapper_json wrapper_rc part_a_json part_a_rc part_b_json part_b_rc
  local ring include_core
  local -a gate_ids=()
  local -a classes=()
  local -a split=()
  local gid

  case "$scope_label" in
    fast)
      ring="$(yq e -r '.profiles.fast.ring // "instant"' "$PROFILE_CONTRACT")"
      while IFS=$'\t' read -r fast_domain class_csv; do
        [[ -n "$fast_domain" ]] || continue
        IFS=',' read -r -a split <<< "$class_csv"
        classes=()
        for gid in "${split[@]-}"; do
          [[ -n "$gid" ]] && classes+=("$gid")
        done
        if [[ "$(normalize_domain "$fast_domain")" == "core" ]]; then
          while IFS= read -r gid; do
            [[ -n "$gid" ]] && gate_ids+=("$gid")
          done < <(collect_core_ids_by_classes "${classes[@]-}")
        else
          while IFS= read -r gid; do
            [[ -n "$gid" ]] && gate_ids+=("$gid")
          done < <(collect_ids_for_domain_and_classes "$fast_domain" "${classes[@]-}")
        fi
      done < <(yq e -r '.profiles.fast.domains[] | [.domain, (.classes | join(","))] | @tsv' "$PROFILE_CONTRACT")

      mapfile -t gate_ids < <(printf '%s\n' "${gate_ids[@]-}" | unique_ids)
      ((${#gate_ids[@]} > 0)) || fail "fast profile resolved zero class-driven gates"
      IFS=$'\t' read -r wrapper_rc wrapper_json < <(run_json_cmd "$VERIFY_TOPOLOGY" ids-run "${gate_ids[@]-}" --ring "$ring")
      ;;
    domain)
      ring="$(yq e -r '.profiles.domain.ring // "standard"' "$PROFILE_CONTRACT")"
      include_core="$(yq e -r '.profiles.domain.include_core_base // true' "$PROFILE_CONTRACT")"

      if [[ "$include_core" == "true" ]]; then
        mapfile -t classes < <(yq e -r '.profiles.domain.core_base.classes[]' "$PROFILE_CONTRACT")
        while IFS= read -r gid; do
          [[ -n "$gid" ]] && gate_ids+=("$gid")
        done < <(collect_core_ids_by_classes "${classes[@]-}")
      fi

      mapfile -t classes < <(yq e -r '.profiles.domain.target.classes[]' "$PROFILE_CONTRACT")
      while IFS= read -r gid; do
        [[ -n "$gid" ]] && gate_ids+=("$gid")
      done < <(collect_ids_for_domain_and_classes "$domain_label" "${classes[@]-}")

      mapfile -t gate_ids < <(printf '%s\n' "${gate_ids[@]-}" | unique_ids)
      ((${#gate_ids[@]} > 0)) || fail "domain profile resolved zero class-driven gates for '$domain_label'"
      IFS=$'\t' read -r wrapper_rc wrapper_json < <(run_json_cmd "$VERIFY_TOPOLOGY" ids-run "${gate_ids[@]-}" --ring "$ring")
      ;;
    release)
      IFS=$'\t' read -r wrapper_rc wrapper_json < <(run_json_cmd "$VERIFY_TOPOLOGY" release)
      ;;
    *) fail "internal scope error: $scope_label" ;;
  esac

  printf '%s\t%s\n' "$wrapper_rc" "$wrapper_json"
}

run_legacy() {
  local scope_label="$1"
  local domain_label="$2"
  local legacy_json legacy_rc part_a_json part_a_rc part_b_json part_b_rc

  case "$scope_label" in
    fast)
      IFS=$'\t' read -r legacy_rc legacy_json < <(run_json_cmd "$VERIFY_TOPOLOGY" core)
      ;;
    domain)
      IFS=$'\t' read -r part_a_rc part_a_json < <(run_json_cmd "$VERIFY_TOPOLOGY" core)
      IFS=$'\t' read -r part_b_rc part_b_json < <(run_json_cmd "$VERIFY_PACK" run "$domain_label")
      legacy_json="$(merge_json_results "$part_a_json" "$part_b_json")"
      if [[ "$part_a_rc" -eq 0 && "$part_b_rc" -eq 0 ]]; then
        legacy_rc=0
      else
        legacy_rc=1
      fi
      ;;
    release)
      IFS=$'\t' read -r legacy_rc legacy_json < <(run_json_cmd "$VERIFY_TOPOLOGY" release)
      ;;
    *) fail "internal scope error: $scope_label" ;;
  esac

  printf '%s\t%s\n' "$legacy_rc" "$legacy_json"
}

parity_diff() {
  local wrapper_json="$1"
  local legacy_json="$2"

  jq -cn --argjson w "$wrapper_json" --argjson l "$legacy_json" '
    {
      total_delta: (($w.total // 0) - ($l.total // 0)),
      pass_delta: (($w.pass // 0) - ($l.pass // 0)),
      fail_delta: (($w.fail // 0) - ($l.fail // 0)),
      wrapper_only_failures: ((($w.failing_ids // []) - ($l.failing_ids // [])) | unique),
      legacy_only_failures: ((($l.failing_ids // []) - ($w.failing_ids // [])) | unique)
    }
  '
}

IFS=$'\t' read -r wrapper_rc wrapper_json < <(run_wrapper "$scope" "$target_domain")

class_json="$(classify_failing_ids "$(jq -c '.failing_ids // []' <<<"$wrapper_json")")"
if jq -e '.status == "fail" and ((.failing_ids // []) | length == 0)' >/dev/null 2>&1 <<<"$wrapper_json"; then
  class_json="$(jq '.deterministic += ["RELEASE_SUITE"]' <<<"$class_json")"
fi
append_history "${scope}${target_domain:+:$target_domain}" "$wrapper_json" "$class_json"
update_gate_pass_streak "$scope" "$target_domain" "$wrapper_json"

legacy_rc=0
legacy_json='{}'
diff_json='{}'
if [[ "$shadow_mode" -eq 1 ]]; then
  IFS=$'\t' read -r legacy_rc legacy_json < <(run_legacy "$scope" "$target_domain")
  diff_json="$(parity_diff "$wrapper_json" "$legacy_json")"
fi

if [[ "$json_mode" -eq 1 ]]; then
  jq -n \
    --arg scope "$scope" \
    --arg domain "$target_domain" \
    --argjson wrapper_rc "$wrapper_rc" \
    --argjson wrapper "$wrapper_json" \
    --argjson shadow "$shadow_mode" \
    --argjson legacy_rc "$legacy_rc" \
    --argjson legacy "$legacy_json" \
    --argjson parity_diff "$diff_json" \
    --argjson failure_class "$class_json" \
    --argjson failing_gate_ids "$(jq -c '.failing_ids // []' <<<"$wrapper_json")" \
    --arg history_file "$HISTORY_FILE" \
    '{scope:$scope,domain:$domain,wrapper_rc:$wrapper_rc,wrapper:$wrapper,failing_gate_ids:$failing_gate_ids,shadow_mode:$shadow,legacy_rc:$legacy_rc,legacy:$legacy,parity_diff:$parity_diff,failure_class:$failure_class,history_file:$history_file}'
else
  echo "verify.run"
  echo "scope: $scope"
  [[ -n "$target_domain" ]] && echo "domain: $target_domain"
  echo "wrapper: total=$(jq -r '.total // 0' <<<"$wrapper_json") pass=$(jq -r '.pass // 0' <<<"$wrapper_json") fail=$(jq -r '.fail // 0' <<<"$wrapper_json")"
  echo "failing_gate_ids: $(jq -r '(.failing_ids // []) | if length == 0 then "none" else join(",") end' <<<"$wrapper_json")"
  echo "failure_class: deterministic=$(jq -r '.deterministic | length' <<<"$class_json") freshness=$(jq -r '.freshness | length' <<<"$class_json") gate_bug=$(jq -r '.gate_bug | length' <<<"$class_json")"
  if [[ "$shadow_mode" -eq 1 ]]; then
    echo "shadow_legacy: total=$(jq -r '.total // 0' <<<"$legacy_json") pass=$(jq -r '.pass // 0' <<<"$legacy_json") fail=$(jq -r '.fail // 0' <<<"$legacy_json")"
    echo "parity_diff: total_delta=$(jq -r '.total_delta // 0' <<<"$diff_json") pass_delta=$(jq -r '.pass_delta // 0' <<<"$diff_json") fail_delta=$(jq -r '.fail_delta // 0' <<<"$diff_json")"
    echo "parity_wrapper_only_failures: $(jq -r '(.wrapper_only_failures // []) | join(",")' <<<"$diff_json")"
    echo "parity_legacy_only_failures: $(jq -r '(.legacy_only_failures // []) | join(",")' <<<"$diff_json")"
  fi
  echo "history_file: $HISTORY_FILE"
fi

exit "$wrapper_rc"
